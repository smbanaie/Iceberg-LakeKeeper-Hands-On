{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pyjwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration:\n",
      "   - Catalog URL: http://lakekeeper:8181/catalog\n",
      "   - Management URL: http://lakekeeper:8181/management\n",
      "   - Warehouse: irisa-ot\n",
      "   - Namespace: irisa\n",
      "   - Table: fake_seclink\n"
     ]
    }
   ],
   "source": [
    "import requests, jwt\n",
    "from IPython.display import JSON\n",
    "from pyiceberg.catalog.rest import RestCatalog\n",
    "import pandas as pd\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.partitioning import PartitionSpec, PartitionField\n",
    "from pyiceberg.types import NestedField, StringType, IntegerType, TimestampType\n",
    "from pyiceberg.transforms import MonthTransform\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pyarrow as pa\n",
    "import duckdb\n",
    "\n",
    "# Authentication and API endpoints\n",
    "CATALOG_URL = \"http://lakekeeper:8181/catalog\"\n",
    "MANAGEMENT_URL = \"http://lakekeeper:8181/management\"\n",
    "KEYCLOAK_TOKEN_URL = \"http://keycloak:8080/realms/iceberg/protocol/openid-connect/token\"\n",
    "\n",
    "# Table configuration\n",
    "WAREHOUSE = \"irisa-ot\"\n",
    "NAMESPACE = \"irisa\"\n",
    "TABLE_NAME = \"fake_seclink\"\n",
    "\n",
    "print(f\"üîß Configuration:\")\n",
    "print(f\"   - Catalog URL: {CATALOG_URL}\")\n",
    "print(f\"   - Management URL: {MANAGEMENT_URL}\")\n",
    "print(f\"   - Warehouse: {WAREHOUSE}\")\n",
    "print(f\"   - Namespace: {NAMESPACE}\")\n",
    "print(f\"   - Table: {TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Authenticating with Keycloak...\n",
      "‚úÖ Authentication successful\n",
      "   - Client: service-account-spark\n",
      "   - Expires: 2025-08-05 10:56:40\n"
     ]
    }
   ],
   "source": [
    "# Login to Keycloak for authentication\n",
    "CLIENT_ID = \"spark\"\n",
    "CLIENT_SECRET = \"2OR3eRvYfSZzzZ16MlPd95jhLnOaLM52\"\n",
    "\n",
    "print(\"üîê Authenticating with Keycloak...\")\n",
    "\n",
    "response = requests.post(\n",
    "    url=KEYCLOAK_TOKEN_URL,\n",
    "    data={\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"client_secret\": CLIENT_SECRET,\n",
    "        \"scope\": \"lakekeeper\"\n",
    "    },\n",
    "    headers={\"Content-type\": \"application/x-www-form-urlencoded\"},\n",
    ")\n",
    "response.raise_for_status()\n",
    "access_token = response.json()['access_token']\n",
    "\n",
    "# Verify the token\n",
    "token_data = jwt.decode(access_token, options={\"verify_signature\": False})\n",
    "print(f\"‚úÖ Authentication successful\")\n",
    "print(f\"   - Client: {token_data.get('preferred_username', 'Unknown')}\")\n",
    "print(f\"   - Expires: {datetime.fromtimestamp(token_data.get('exp', 0))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Setting up warehouse...\n",
      "‚úÖ Warehouse 'irisa-ot' created successfully\n"
     ]
    }
   ],
   "source": [
    "# Create or verify warehouse exists\n",
    "print(\"üèóÔ∏è Setting up warehouse...\")\n",
    "\n",
    "warehouse_config = {\n",
    "    \"warehouse-name\": WAREHOUSE,\n",
    "    \"storage-profile\": {\n",
    "        \"type\": \"s3\",\n",
    "        \"bucket\": \"irisa-warehouse\",\n",
    "        \"key-prefix\": \"ot\",\n",
    "        \"endpoint\": \"http://minio:9000\",\n",
    "        \"region\": \"local-01\",\n",
    "        \"path-style-access\": True,\n",
    "        \"flavor\": \"minio\",\n",
    "        \"sts-enabled\": True\n",
    "    },\n",
    "    \"storage-credential\": {\n",
    "        \"type\": \"s3\",\n",
    "        \"credential-type\": \"access-key\",\n",
    "        \"aws-access-key-id\": \"minio-root-user\",\n",
    "        \"aws-secret-access-key\": \"minio-root-password\"\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        url=f\"{MANAGEMENT_URL}/v1/warehouse\",\n",
    "        headers={\"Authorization\": f\"Bearer {access_token}\"},\n",
    "        json=warehouse_config\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(f\"‚úÖ Warehouse '{WAREHOUSE}' created successfully\")\n",
    "    JSON(response.json())\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    if e.response.status_code == 409 or e.response.status_code==400 :  # Already exists\n",
    "        print(f\"‚ÑπÔ∏è Warehouse '{WAREHOUSE}' already exists\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Catalog initialized successfully with authentication\n",
      "Available namespaces: []\n"
     ]
    }
   ],
   "source": [
    "# Initialize the catalog with authenticated access\n",
    "catalog = RestCatalog(\n",
    "    name=\"irisa_catalog\",\n",
    "    warehouse=WAREHOUSE,\n",
    "    uri=CATALOG_URL,\n",
    "    token=access_token,  # Use the real access token\n",
    ")\n",
    "\n",
    "print(\"‚úì Catalog initialized successfully with authentication\")\n",
    "print(f\"Available namespaces: {list(catalog.list_namespaces())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Created namespace: irisa\n",
      "üìã Available namespaces: [('irisa',)]\n"
     ]
    }
   ],
   "source": [
    "# Create the irisa namespace if it doesn't exist\n",
    "irisa_namespace = (NAMESPACE,)\n",
    "\n",
    "if irisa_namespace not in catalog.list_namespaces():\n",
    "    catalog.create_namespace(irisa_namespace)\n",
    "    print(f\"‚úì Created namespace: {NAMESPACE}\")\n",
    "else:\n",
    "    print(f\"‚Ñπ Namespace '{NAMESPACE}' already exists\")\n",
    "\n",
    "print(f\"üìã Available namespaces: {list(catalog.list_namespaces())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Schema Defined:\n",
      "   - Total fields: 7\n",
      "   - Id: int\n",
      "   - TelegramCode: int\n",
      "   - Source: int\n",
      "   - Destination: int\n",
      "   - DateIn: timestamp\n",
      "   - DateOut: timestamp\n",
      "   - Body: string\n",
      "   - Note: Timestamps use microsecond precision for Iceberg compatibility\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for fake_seclink with proper timestamp handling\n",
    "schema = Schema(\n",
    "    NestedField(field_id=1, name=\"Id\", field_type=IntegerType(), required=True),\n",
    "    NestedField(field_id=2, name=\"TelegramCode\", field_type=IntegerType(), required=False),\n",
    "    NestedField(field_id=3, name=\"Source\", field_type=IntegerType(), required=False),\n",
    "    NestedField(field_id=4, name=\"Destination\", field_type=IntegerType(), required=False),\n",
    "    NestedField(field_id=5, name=\"DateIn\", field_type=TimestampType(), required=False),\n",
    "    NestedField(field_id=6, name=\"DateOut\", field_type=TimestampType(), required=False),\n",
    "    NestedField(field_id=7, name=\"Body\", field_type=StringType(), required=False),\n",
    ")\n",
    "\n",
    "print(\" Schema Defined:\")\n",
    "print(f\"   - Total fields: {len(schema.fields)}\")\n",
    "for field in schema.fields:\n",
    "   print(f\"   - {field.name}: {field.field_type}\")\n",
    "print(\"   - Note: Timestamps use microsecond precision for Iceberg compatibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Partitioning Strategy:\n",
      "   - Partition by: month(DateIn)\n",
      "   - Total partition fields: 1\n",
      "   - Benefits: Efficient time-based queries and data organization\n",
      "   - Storage optimization: Data automatically organized by month\n"
     ]
    }
   ],
   "source": [
    "# Define partitioning strategy (by month of DateIn)\n",
    "partition_spec = PartitionSpec(\n",
    "    PartitionField(\n",
    "        source_id=5,  # DateIn field ID\n",
    "        field_id=1000,\n",
    "        name=\"DateIn_month\",\n",
    "        transform=MonthTransform()\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"üîß Partitioning Strategy:\")\n",
    "print(f\"   - Partition by: month(DateIn)\")\n",
    "print(f\"   - Total partition fields: {len(partition_spec.fields)}\")\n",
    "print(\"   - Benefits: Efficient time-based queries and data organization\")\n",
    "print(\"   - Storage optimization: Data automatically organized by month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table created successfully!\n",
      "   - Table: irisa.fake_seclink\n",
      "   - Location: s3://irisa-warehouse/ot/019879aa-2424-7971-91d8-0391f81fb93c/019879aa-3468-7de3-b17f-422dd2dba480\n",
      "   - Format: 2\n",
      "   - Partitioning: 1 fields\n",
      "   - Authentication: Using Keycloak token\n"
     ]
    }
   ],
   "source": [
    "# Create the table with proper authentication\n",
    "table_identifier = (NAMESPACE, TABLE_NAME)\n",
    "\n",
    "# Check if table already exists\n",
    "if table_identifier in catalog.list_tables(namespace=irisa_namespace):\n",
    "    print(f\"‚ö† Table '{TABLE_NAME}' already exists in namespace '{NAMESPACE}'\")\n",
    "    print(\"   Dropping existing table...\")\n",
    "    catalog.drop_table(table_identifier)\n",
    "    print(\"   ‚úì Existing table dropped\")\n",
    "\n",
    "# Create the new table\n",
    "try:\n",
    "    table = catalog.create_table(\n",
    "        identifier=table_identifier,\n",
    "        schema=schema,\n",
    "        partition_spec=partition_spec\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Table created successfully!\")\n",
    "    print(f\"   - Table: {NAMESPACE}.{TABLE_NAME}\")\n",
    "    print(f\"   - Location: {table.location()}\")\n",
    "    print(f\"   - Format: {table.format_version}\")\n",
    "    print(f\"   - Partitioning: {len(partition_spec.fields)} fields\")\n",
    "    print(f\"   - Authentication: Using Keycloak token\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating table: {str(e)}\")\n",
    "    print(\"   - Check warehouse configuration and permissions\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Generating fake data...\n",
      "üîß Converting timestamps to microsecond precision...\n",
      "‚úÖ Timestamps converted to microsecond precision\n",
      "‚úÖ Generated 10000 fake records\n",
      ">> Date range: 2024-01-01 to 2024-06-30\n",
      "üìä Sample data:\n",
      "   Id  TelegramCode  Source  Destination              DateIn  \\\n",
      "0   1          7379       2            4 2024-02-13 05:01:22   \n",
      "1   2          7416       2            2 2024-05-29 10:32:40   \n",
      "2   3          6101       4            2 2024-04-07 09:41:36   \n",
      "3   4          1871       3            5 2024-02-13 11:49:13   \n",
      "4   5          9576       5            2 2024-05-13 18:52:24   \n",
      "\n",
      "              DateOut                                               Body  \n",
      "0 2024-02-13 05:56:22  Message body for record 1 from source 2 to des...  \n",
      "1 2024-05-29 10:47:40  Message body for record 2 from source 3 to des...  \n",
      "2 2024-04-07 10:00:36  Message body for record 3 from source 2 to des...  \n",
      "3 2024-02-13 12:21:13  Message body for record 4 from source 4 to des...  \n",
      "4 2024-05-13 19:33:24  Message body for record 5 from source 4 to des...  \n",
      "\n",
      "üìà Monthly distribution:\n",
      "   - 2024-01: 1711 records\n",
      "   - 2024-02: 1616 records\n",
      "   - 2024-03: 1685 records\n",
      "   - 2024-04: 1641 records\n",
      "   - 2024-05: 1660 records\n",
      "   - 2024-06: 1687 records\n"
     ]
    }
   ],
   "source": [
    "# Generate fake data for 6 months (10,000 records)\n",
    "print(\"üé≤ Generating fake data...\")\n",
    "\n",
    "# Set up date range for 6 months\n",
    "start_date = datetime(2024, 1, 1)\n",
    "end_date = datetime(2024, 6, 30)\n",
    "total_records = 10000\n",
    "\n",
    "# Generate random data\n",
    "data = []\n",
    "for i in range(total_records):\n",
    "    # Random date within the 6-month period\n",
    "    random_days = random.randint(0, (end_date - start_date).days)\n",
    "    date_in = start_date + timedelta(days=random_days)\n",
    "\n",
    "    # Random time within the day\n",
    "    random_hours = random.randint(0, 23)\n",
    "    random_minutes = random.randint(0, 59)\n",
    "    random_seconds = random.randint(0, 59)\n",
    "    date_in = date_in.replace(hour=random_hours, minute=random_minutes, second=random_seconds)\n",
    "\n",
    "    # DateOut is typically 1-60 minutes after DateIn\n",
    "    random_duration = random.randint(1, 60)\n",
    "    date_out = date_in + timedelta(minutes=random_duration)\n",
    "\n",
    "    record = {\n",
    "        \"Id\": i + 1,\n",
    "        \"TelegramCode\": random.randint(1000, 9999),\n",
    "        \"Source\": random.randint(1, 5),\n",
    "        \"Destination\": random.randint(1, 5),\n",
    "        \"DateIn\": date_in,\n",
    "        \"DateOut\": date_out,\n",
    "        \"Body\": f\"Message body for record {i + 1} from source {random.randint(1, 5)} to destination {random.randint(1, 5)}\"\n",
    "    }\n",
    "    data.append(record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# üîß CRITICAL FIX: Convert timestamps to microsecond precision\n",
    "print(\"üîß Converting timestamps to microsecond precision...\")\n",
    "df['DateIn'] = df['DateIn'].dt.floor('us')\n",
    "df['DateOut'] = df['DateOut'].dt.floor('us')\n",
    "print(\"‚úÖ Timestamps converted to microsecond precision\")\n",
    "\n",
    "print(f\"‚úÖ Generated {len(df)} fake records\")\n",
    "print(f\">> Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"üìä Sample data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Show distribution by month\n",
    "monthly_distribution = df['DateIn'].dt.to_period('M').value_counts().sort_index()\n",
    "print(f\"\\nüìà Monthly distribution:\")\n",
    "for month, count in monthly_distribution.items():\n",
    "    print(f\"   - {month}: {count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Inserting data into Iceberg table...\n",
      "‚úÖ PyArrow table created with microsecond precision timestamps\n",
      "‚úÖ Successfully inserted 10000 records into irisa.fake_seclink\n",
      "   - Authentication: Using Keycloak token\n",
      "   - Warehouse: irisa-ot\n",
      "\n",
      "üîç Data insertion completed successfully!\n",
      "üìä Expected records: 10000\n",
      "‚úÖ Table: irisa.fake_seclink is ready for queries!\n"
     ]
    }
   ],
   "source": [
    "# Insert data into the Iceberg table with proper authentication\n",
    "print(\"üì§ Inserting data into Iceberg table...\")\n",
    "\n",
    "try:\n",
    "    # Load the table (now with authenticated access)\n",
    "    table = catalog.load_table(table_identifier)\n",
    "\n",
    "    # üîß CRITICAL FIX: Convert DataFrame to PyArrow table with explicit microsecond precision schema\n",
    "    arrow_table = pa.Table.from_pandas(df, schema=pa.schema([\n",
    "        pa.field(\"Id\", pa.int32(), nullable=False),  # Required field\n",
    "        pa.field(\"TelegramCode\", pa.int32(), nullable=True),\n",
    "        pa.field(\"Source\", pa.int32(), nullable=True),\n",
    "        pa.field(\"Destination\", pa.int32(), nullable=True),\n",
    "        pa.field(\"DateIn\", pa.timestamp('us'), nullable=True),  # Microsecond precision\n",
    "        pa.field(\"DateOut\", pa.timestamp('us'), nullable=True),  # Microsecond precision\n",
    "        pa.field(\"Body\", pa.string(), nullable=True),\n",
    "    ]))\n",
    "\n",
    "    print(\"‚úÖ PyArrow table created with microsecond precision timestamps\")\n",
    "\n",
    "    # Append data to the table\n",
    "    table.append(arrow_table)\n",
    "\n",
    "    print(f\"‚úÖ Successfully inserted {len(df)} records into {NAMESPACE}.{TABLE_NAME}\")\n",
    "    print(f\"   - Authentication: Using Keycloak token\")\n",
    "    print(f\"   - Warehouse: {WAREHOUSE}\")\n",
    "\n",
    "    # Simple verification\n",
    "    print(f\"\\nüîç Data insertion completed successfully!\")\n",
    "    print(f\"üìä Expected records: {len(df)}\")\n",
    "    print(f\"‚úÖ Table: {NAMESPACE}.{TABLE_NAME} is ready for queries!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inserting data: {str(e)}\")\n",
    "    print(\"   - Check authentication and warehouse permissions\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
