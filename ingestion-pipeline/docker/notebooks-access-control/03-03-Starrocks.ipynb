{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q starrocks \"sqlalchemy<3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This CATALOG_URL works for the \"docker compose\" testing and development environment\n",
    "# Change 'lakekeeper' if you are not running on \"docker compose\" (f. ex. 'localhost' if Lakekeeper is running locally).\n",
    "CATALOG_URL = \"http://lakekeeper:8181/catalog\"\n",
    "STARROCKS_URI = \"starrocks://root@starrocks:9030\"\n",
    "KEYCLOAK_TOKEN_ENDPOINT = \"http://keycloak:8080/realms/iceberg/protocol/openid-connect/token\"\n",
    "WAREHOUSE = \"irisa-ot\"  # Changed to match other notebooks\n",
    "\n",
    "CLIENT_ID = \"starrocks\"\n",
    "CLIENT_SECRET = \"X5IWbfDJBTcU1F3PGZWgxDJwLyuFQmSf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Starrocks Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(STARROCKS_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StarRocks Catalog\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"DROP CATALOG IF EXISTS lakekeeper\"))\n",
    "    connection.execute(\n",
    "        text(f\"\"\"\n",
    "        CREATE EXTERNAL CATALOG lakekeeper\n",
    "        PROPERTIES\n",
    "        (\n",
    "            \"type\" = \"iceberg\",\n",
    "            \"iceberg.catalog.type\" = \"rest\",\n",
    "            \"iceberg.catalog.uri\" = \"{CATALOG_URL}\",\n",
    "            \"iceberg.catalog.warehouse\" = \"{WAREHOUSE}\",\n",
    "            \"iceberg.catalog.oauth2-server-uri\" = \"{KEYCLOAK_TOKEN_ENDPOINT}\",\n",
    "            \"iceberg.catalog.credential\" = \"{CLIENT_ID}:{CLIENT_SECRET}\",\n",
    "            \"iceberg.catalog.scope\" = \"lakekeeper offline_access\",\n",
    "            \"aws.s3.region\" = \"local\",\n",
    "            \"aws.s3.enable_path_style_access\" = \"true\",\n",
    "            \"aws.s3.endpoint\" = \"http://minio:9000\",\n",
    "            \"aws.s3.access_key\" = \"minio-root-user\",\n",
    "            \"aws.s3.secret_key\" = \"minio-root-password\"\n",
    "        )\n",
    "        \"\"\")\n",
    "    )\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Write Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema to match other notebooks\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"CREATE SCHEMA IF NOT EXISTS irisa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Query 1: Total record count\n",
      "Total records: 10000\n"
     ]
    }
   ],
   "source": [
    "# Query 1: Total record count\n",
    "print(\"ðŸ“Š Query 1: Total record count\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    total_count = connection.execute(\n",
    "        text(\"SELECT COUNT(*) FROM irisa.fake_seclink\")\n",
    "    ).fetchone()[0]\n",
    "    print(f\"Total records: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“… Query 2: Records by month (partitioning test)\n",
      "Month 1 (2024-01): 1709 records\n",
      "Month 2 (2024-02): 1572 records\n",
      "Month 3 (2024-03): 1696 records\n",
      "Month 4 (2024-04): 1622 records\n",
      "Month 5 (2024-05): 1754 records\n",
      "Month 6 (2024-06): 1647 records\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Records by month (partitioning test)\n",
    "print(\"ðŸ“… Query 2: Records by month (partitioning test)\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    for month in range(1, 7):\n",
    "        result = connection.execute(\n",
    "            text(f\"\"\"\n",
    "                SELECT COUNT(*) FROM irisa.fake_seclink\n",
    "                WHERE EXTRACT(MONTH FROM DateIn) = {month} AND EXTRACT(YEAR FROM DateIn) = 2024\n",
    "            \"\"\")\n",
    "        ).fetchone()[0]\n",
    "        print(f\"Month {month} (2024-{month:02d}): {result} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¢ Query 3: Top sources by record count\n",
      "Source 5: 2035 records\n",
      "Source 4: 2015 records\n",
      "Source 3: 2014 records\n",
      "Source 2: 1973 records\n",
      "Source 1: 1963 records\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Top sources by record count\n",
    "print(\"ðŸ¢ Query 3: Top sources by record count\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    top_sources = connection.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT Source, COUNT(*) as count\n",
    "            FROM irisa.fake_seclink\n",
    "            GROUP BY Source\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 5\n",
    "        \"\"\")\n",
    "    ).fetchall()\n",
    "    for source, count in top_sources:\n",
    "        print(f\"Source {source}: {count} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ Query 4: Average processing time analysis\n",
      "Average processing time: 30.62 minutes\n",
      "Min processing time: 1.00 minutes\n",
      "Max processing time: 60.00 minutes\n"
     ]
    }
   ],
   "source": [
    "# Query 4: Average processing time analysis\n",
    "print(\"â±ï¸ Query 4: Average processing time analysis\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    avg_stats = connection.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT \n",
    "                AVG(TIMESTAMPDIFF(MINUTE, DateIn, DateOut)) as avg_min,\n",
    "                MIN(TIMESTAMPDIFF(MINUTE, DateIn, DateOut)) as min_min,\n",
    "                MAX(TIMESTAMPDIFF(MINUTE, DateIn, DateOut)) as max_min\n",
    "            FROM irisa.fake_seclink\n",
    "            WHERE DateOut IS NOT NULL AND DateIn IS NOT NULL\n",
    "        \"\"\")\n",
    "    ).fetchone()\n",
    "    print(f\"Average processing time: {avg_stats[0]:.2f} minutes\")\n",
    "    print(f\"Min processing time: {avg_stats[1]:.2f} minutes\")\n",
    "    print(f\"Max processing time: {avg_stats[2]:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ• Query 5: Busiest hour of the day\n",
      "Busiest hour: 6:00 with 465 records\n"
     ]
    }
   ],
   "source": [
    "# Query 5: Busiest hour of the day\n",
    "print(\"ðŸ• Query 5: Busiest hour of the day\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    hour_stats = connection.execute(\n",
    "        text(\"\"\"\n",
    "            SELECT EXTRACT(HOUR FROM DateIn) as hour_of_day, COUNT(*) as count\n",
    "            FROM irisa.fake_seclink\n",
    "            GROUP BY EXTRACT(HOUR FROM DateIn)\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 1\n",
    "        \"\"\")\n",
    "    ).fetchone()\n",
    "    print(f\"Busiest hour: {int(hour_stats[0])}:00 with {hour_stats[1]} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Sample of recent records\n",
      "(3, 4904, 5, 3, datetime.datetime(2024, 2, 17, 20, 10, 29), datetime.datetime(2024, 2, 17, 20, 40, 29), 'Message body for record 3 from source 4 to destination 4')\n",
      "(4, 3079, 2, 5, datetime.datetime(2024, 2, 27, 7, 1, 34), datetime.datetime(2024, 2, 27, 7, 30, 34), 'Message body for record 4 from source 3 to destination 3')\n",
      "(9, 3701, 1, 4, datetime.datetime(2024, 2, 29, 8, 53, 19), datetime.datetime(2024, 2, 29, 8, 56, 19), 'Message body for record 9 from source 4 to destination 3')\n",
      "(14, 8168, 3, 1, datetime.datetime(2024, 2, 9, 14, 50, 19), datetime.datetime(2024, 2, 9, 15, 22, 19), 'Message body for record 14 from source 1 to destination 5')\n",
      "(17, 1113, 2, 4, datetime.datetime(2024, 2, 12, 6, 6, 55), datetime.datetime(2024, 2, 12, 6, 16, 55), 'Message body for record 17 from source 5 to destination 4')\n"
     ]
    }
   ],
   "source": [
    "# Sample data query\n",
    "print(\"ðŸ“‹ Sample of recent records\")\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"SET CATALOG lakekeeper\"))\n",
    "    recent_records = connection.execute(\n",
    "        text(\"SELECT * FROM irisa.fake_seclink LIMIT 5\")\n",
    "    ).fetchall()\n",
    "    for record in recent_records:\n",
    "        print(record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
