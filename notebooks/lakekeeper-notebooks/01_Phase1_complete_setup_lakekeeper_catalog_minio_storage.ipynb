{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Banking Reconciliation Setup - Phase 1\n",
    "## Lakekeeper MinIO S3-backed Iceberg Catalog that uses Postgres as metadata manager.\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "This notebook demonstrates how to set up Apache Iceberg with a **MinIO S3-compatible object storage catalog** for a banking reconciliation system. You will learn:\n",
    "\n",
    "### **Apache Iceberg Fundamentals**\n",
    "- **Catalog System**: Understanding how Iceberg catalogs work with S3/MinIO - Postgres\n",
    "- **MinIO Storage**: How Iceberg stores metadata and data in MinIO buckets\n",
    "- **Table Structure**: The file organization created by Iceberg tables in S3\n",
    "- **Partitioning**: How Iceberg handles partitioned tables\n",
    "\n",
    "### **What You'll Build**\n",
    "- A complete banking reconciliation system with three core tables\n",
    "- S3-based storage with MinIO integration\n",
    "- Partitioned tables for efficient querying\n",
    "- Comprehensive audit trail and validation\n",
    "\n",
    "### **Key Concepts Explained**\n",
    "\n",
    "#### **1. Iceberg Catalog with MinIO (S3)**\n",
    "```python\n",
    "spark.sql.catalog.minio.type = \"hadoop\"\n",
    "spark.sql.catalog.minio.warehouse = \"s3a://warehouse/\"\n",
    "```\n",
    "- **Catalog**: A namespace for tables, schemas, and functions\n",
    "- **MinIO**: S3-compatible object storage for all table data and metadata\n",
    "- **Warehouse**: Data and metadata stored in MinIO buckets\n",
    "\n",
    "#### **2. File Structure Created by Iceberg in S3**\n",
    "\n",
    "```\n",
    "s3a://warehouse/banking/table_name/\n",
    "├── metadata/ # Table metadata and version history\n",
    "│ ├── v1.metadata.json # Current table schema and properties\n",
    "│ ├── version-hint.text # Points to latest metadata version\n",
    "│ └── ..crc # Checksums for data integrity\n",
    "├── data/ # Actual data files (Parquet format)\n",
    "│ └── partition_paths/ # Partitioned data organized by partition keys\n",
    "└── snapshots/ # Table snapshots for time travel\n",
    "```\n",
    "\n",
    "\n",
    "#### **3. Partitioning Strategy**\n",
    "- **source_transactions**: Partitioned by `days(transaction_date)` and `source_system`\n",
    "- **reconciliation_results**: Partitioned by `days(reconciliation_timestamp)` and `match_status`\n",
    "- **reconciliation_batches**: No partitioning (small lookup table)\n",
    "\n",
    "## Phase 1: Foundation Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "**Purpose**: Import all necessary libraries for Spark, MinIO, and file operations.\n",
    "\n",
    "**Key Libraries**:\n",
    "- `pyspark.sql.SparkSession`: Core Spark functionality\n",
    "- `boto3`: AWS S3/MinIO client for object storage\n",
    "- `os`, `json`, `datetime`: File and data manipulation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Spark Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> - Spark Minor Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span> - Iceberg Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Spark Version: \u001b[1;36m3.5\u001b[0m.\u001b[1;36m6\u001b[0m - Spark Minor Version: \u001b[1;36m3.5\u001b[0m - Iceberg Version: \u001b[1;36m1.9\u001b[0m.\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "!pip install --root-user-action=ignore rich --quiet\n",
    "from rich import print\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# This CATALOG_URL works for the \"docker compose\" testing and development environment\n",
    "# Change 'lakekeeper' if you are not running on \"docker compose\" (f. ex. 'localhost' if Lakekeeper is running locally).\n",
    "CATALOG_URL = \"http://lakekeeper:8181/catalog\"\n",
    "WAREHOUSE = \"irisa-ot\" # as is in lakekeeper : http://localhost:8181/ui/warehouse\n",
    "\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.9.2\"\n",
    "\n",
    "print(f\"Spark Version: {SPARK_VERSION} - Spark Minor Version: {SPARK_MINOR_VERSION} - Iceberg Version: {ICEBERG_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Stop any existing Spark session\n",
    "\n",
    "**Purpose**: Ensure a clean Spark environment by stopping any existing sessions.\n",
    "\n",
    "**Why This Matters**:\n",
    "- Prevents configuration conflicts\n",
    "- Ensures fresh Iceberg catalog initialization\n",
    "- Clears any cached metadata or connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/21 12:46:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Stopped existing Spark session\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Stopped existing Spark session\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stop any existing Spark session\n",
    "try:\n",
    "    SparkSession.builder.getOrCreate().stop()\n",
    "    print(\"✓ Stopped existing Spark session\")\n",
    "except:\n",
    "    print(\"ℹ No existing Spark session to stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Spark Session with Iceberg + MinIO (S3) Configuration\n",
    "\n",
    "**Purpose**: Initialize Spark with Apache Iceberg extensions and MinIO S3-compatible catalog configuration.\n",
    "\n",
    "### **Configuration Breakdown**:\n",
    "\n",
    "#### **Iceberg Extensions**\n",
    "```python\n",
    "spark.sql.extensions = \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n",
    "```\n",
    "- Enables Iceberg-specific SQL commands (CREATE TABLE, MERGE, etc.)\n",
    "- Provides time travel, schema evolution, and partition evolution capabilities\n",
    "\n",
    "#### **Catalog Configuration**\n",
    "```python\n",
    "spark.sql.catalog.minio = \"org.apache.iceberg.spark.SparkCatalog\"\n",
    "spark.sql.catalog.minio.type = \"hadoop\"\n",
    "spark.sql.catalog.minio.warehouse = \"s3a://warehouse/\"\n",
    "spark.hadoop.fs.s3a.endpoint = \"http://minio:9000\"\n",
    "spark.hadoop.fs.s3a.access.key = \"minio\"\n",
    "spark.hadoop.fs.s3a.secret.key = \"minio123\"\n",
    "spark.hadoop.fs.s3a.path.style.access = \"true\"\n",
    "spark.hadoop.fs.s3a.impl = \"org.apache.hadoop.fs.s3a.S3AFileSystem\"\n",
    "```\n",
    "- **minio**: Our custom catalog name for S3/MinIO\n",
    "- **warehouse**: S3 bucket path for table data and metadata\n",
    "\n",
    "#### **Default Catalog**\n",
    "- You will use `lakekeeper` as the catalog name in all SQL operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Spark session created successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Spark session created successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Spark version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Spark version: \u001b[1;36m3.5\u001b[0m.\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Default catalog: lakekeeper\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Default catalog: lakekeeper\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create warehouse directory if it doesn't exist\n",
    "config = {\n",
    "    f\"spark.sql.catalog.lakekeeper\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    f\"spark.sql.catalog.lakekeeper.type\": \"rest\",\n",
    "    f\"spark.sql.catalog.lakekeeper.uri\": CATALOG_URL,\n",
    "    f\"spark.sql.catalog.lakekeeper.warehouse\": WAREHOUSE,\n",
    "    f\"spark.sql.catalog.lakekeeper.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.defaultCatalog\": \"lakekeeper\",\n",
    "    \"spark.executor.memory\": \"1024m\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.jars.packages\": f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION}\",\n",
    "}\n",
    "\n",
    "spark_config = SparkConf().setMaster('spark://spark-master:7077').setAppName(\"Iceberg-REST-Cluster-Banking-Sample-Phase1\")\n",
    "for k, v in config.items():\n",
    "    spark_config = spark_config.set(k, v)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_config).getOrCreate()\n",
    "\n",
    "spark.sql(\"USE lakekeeper\")\n",
    "print(\"✓ Spark session created successfully\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Default catalog: {spark.conf.get('spark.sql.defaultCatalog')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize MinIO Client and Check Health\n",
    "\n",
    "**Purpose**: Set up MinIO (S3-compatible object storage) for future data operations.\n",
    "\n",
    "### **MinIO Configuration**:\n",
    "- **Endpoint**: `http://minio:9000` (Docker service name)\n",
    "- **Credentials**: `minio`/`minio123` (default development credentials)\n",
    "- **Region**: `us-east-1` (standard region)\n",
    "- **Signature Version**: `s3v4` (AWS Signature Version 4)\n",
    "\n",
    "### **Health Check Strategy**:\n",
    "- Retry logic with exponential backoff\n",
    "- Graceful handling of connection failures\n",
    "- Detailed logging for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.39.9-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.40.0,>=1.39.9 (from boto3)\n",
      "  Downloading botocore-1.39.9-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/bitnami/python/lib/python3.12/site-packages (from botocore<1.40.0,>=1.39.9->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/bitnami/python/lib/python3.12/site-packages (from botocore<1.40.0,>=1.39.9->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/bitnami/python/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.9->boto3) (1.17.0)\n",
      "Downloading boto3-1.39.9-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.39.9-py3-none-any.whl (13.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [boto3]32m3/4\u001b[0m [boto3]sfer]\n",
      "\u001b[1A\u001b[2KSuccessfully installed boto3-1.39.9 botocore-1.39.9 jmespath-1.0.1 s3transfer-0.13.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ MinIO client initialized\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ MinIO client initialized\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Endpoint: <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://minio:9000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Endpoint: \u001b[4;94mhttp://minio:9000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Signature Version: s3v4\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Signature Version: s3v4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "# Initialize MinIO client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minio-root-user',\n",
    "    aws_secret_access_key='minio-root-password',\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "print(\"✓ MinIO client initialized\")\n",
    "print(f\"Endpoint: http://minio:9000\")\n",
    "print(f\"Signature Version: s3v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Checking MinIO health<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Checking MinIO health\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ MinIO is ready! Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> existing buckets\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ MinIO is ready! Found \u001b[1;36m1\u001b[0m existing buckets\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check MinIO health with retries\n",
    "print(\"Checking MinIO health...\")\n",
    "max_attempts = 30\n",
    "attempt = 1\n",
    "\n",
    "while attempt <= max_attempts:\n",
    "    try:\n",
    "        # Try to list buckets to check connectivity\n",
    "        buckets = s3_client.list_buckets()\n",
    "        print(f\"✓ MinIO is ready! Found {len(buckets['Buckets'])} existing buckets\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Waiting for MinIO... (attempt {attempt}/{max_attempts}): {str(e)}\")\n",
    "        if attempt >= max_attempts:\n",
    "            print(\"⚠ MinIO failed to start within the expected time. Continuing anyway...\")\n",
    "            break\n",
    "        time.sleep(2)\n",
    "        attempt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Banking Namespace\n",
    "\n",
    "**Purpose**: Create a logical namespace to organize related tables in MinIO.\n",
    "\n",
    "### **Namespace Benefits**:\n",
    "- **Organization**: Groups related tables together\n",
    "- **Access Control**: Apply permissions at namespace level\n",
    "- **Naming**: Avoid table name conflicts\n",
    "- **Discovery**: Easier to find related tables\n",
    "\n",
    "### **S3 Impact**:\n",
    "The namespace creates a directory structure in your MinIO bucket:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Created namespace: lakekeeper.banking\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Created namespace: lakekeeper.banking\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Namespace location: lakekeeper/banking\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Namespace location: lakekeeper/banking\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the banking namespace\n",
    "try:\n",
    "    spark.sql(\"CREATE NAMESPACE IF NOT EXISTS lakekeeper.banking\")\n",
    "    print(\"✓ Created namespace: lakekeeper.banking\")\n",
    "    print(f\"Namespace location: lakekeeper/banking\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating namespace: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5b: Verify Namespace Creation \n",
    "\n",
    "**Purpose**: Confirm that the namespace has been created in the Lakekeeper catalog.\n",
    "\n",
    "> Note: click on `irisa-ot` on `http://localhost:8181/ui/warehouse` \n",
    "\n",
    "**also checkout the lakekeeper postgres database :** `namespace` table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Iceberg Tables \n",
    "\n",
    "**Purpose**: Create the core tables for the banking reconciliation system in the Lakekeeper and MinIO.\n",
    "\n",
    "### **Table Design Strategy**:\n",
    "\n",
    "#### **1. source_transactions**\n",
    "- **Purpose**: Store all transaction data from different source systems\n",
    "- **Partitioning**: By `days(transaction_date)` and `source_system`\n",
    "- **Benefits**: Efficient querying by date range and source\n",
    "- **Schema**: Comprehensive transaction metadata\n",
    "\n",
    "#### **2. reconciliation_results**\n",
    "- **Purpose**: Store reconciliation outcomes and discrepancies\n",
    "- **Partitioning**: By `days(reconciliation_timestamp)` and `match_status`\n",
    "- **Benefits**: Easy analysis of reconciliation performance\n",
    "- **Schema**: Detailed discrepancy tracking\n",
    "\n",
    "#### **3. reconciliation_batches**\n",
    "- **Purpose**: Track reconciliation batch metadata\n",
    "- **Partitioning**: None (small lookup table)\n",
    "- **Benefits**: Batch-level monitoring and reporting\n",
    "- **Schema**: Batch execution metadata\n",
    "\n",
    "> All tables will be created under the `minio.banking` namespace and stored in your MinIO S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating source_transactions table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating source_transactions table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Created table: lakekeeper.banking.source_transactions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Created table: lakekeeper.banking.source_transactions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">days</span><span style=\"font-weight: bold\">(</span>transaction_date<span style=\"font-weight: bold\">)</span>, source_system\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[1;35mdays\u001b[0m\u001b[1m(\u001b[0mtransaction_date\u001b[1m)\u001b[0m, source_system\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Store all transaction data from different sources\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Store all transaction data from different sources\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create source_transactions table\n",
    "print(\"Creating source_transactions table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.source_transactions (\n",
    "      transaction_id STRING,\n",
    "      source_system STRING,\n",
    "      transaction_date TIMESTAMP,\n",
    "      amount DECIMAL(18,2),\n",
    "      account_id STRING,\n",
    "      transaction_type STRING,\n",
    "      reference_id STRING,\n",
    "      status STRING,\n",
    "      payload STRING,\n",
    "      created_at TIMESTAMP,\n",
    "      processing_timestamp TIMESTAMP\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (days(transaction_date), source_system)\n",
    "    \"\"\")\n",
    "    print(\"✓ Created table: lakekeeper.banking.source_transactions\")\n",
    "    print(\"  - Partitioned by: days(transaction_date), source_system\")\n",
    "    print(\"  - Purpose: Store all transaction data from different sources\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating source_transactions table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating reconciliation_results table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating reconciliation_results table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Created table: lakekeeper.banking.reconciliation_results\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Created table: lakekeeper.banking.reconciliation_results\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">days</span><span style=\"font-weight: bold\">(</span>reconciliation_timestamp<span style=\"font-weight: bold\">)</span>, match_status\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[1;35mdays\u001b[0m\u001b[1m(\u001b[0mreconciliation_timestamp\u001b[1m)\u001b[0m, match_status\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Store reconciliation outcomes and discrepancies\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Store reconciliation outcomes and discrepancies\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create reconciliation_results table\n",
    "print(\"Creating reconciliation_results table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.reconciliation_results (\n",
    "      reconciliation_id STRING,\n",
    "      batch_id STRING,\n",
    "      primary_transaction_id STRING,\n",
    "      secondary_transaction_id STRING,\n",
    "      match_status STRING,\n",
    "      discrepancy_type STRING,\n",
    "      discrepancy_amount DECIMAL(18,2),\n",
    "      reconciliation_timestamp TIMESTAMP,\n",
    "      notes STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (days(reconciliation_timestamp), match_status)\n",
    "    \"\"\")\n",
    "    print(\"✓ Created table: lakekeeper.banking.reconciliation_results\")\n",
    "    print(\"  - Partitioned by: days(reconciliation_timestamp), match_status\")\n",
    "    print(\"  - Purpose: Store reconciliation outcomes and discrepancies\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating reconciliation_results table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating reconciliation_batches table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating reconciliation_batches table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✓ Created table: lakekeeper.banking.reconciliation_batches\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✓ Created table: lakekeeper.banking.reconciliation_batches\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> <span style=\"font-weight: bold\">(</span>small lookup table<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[3;35mNone\u001b[0m \u001b[1m(\u001b[0msmall lookup table\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Track reconciliation batch metadata\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Track reconciliation batch metadata\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create reconciliation_batches table\n",
    "print(\"Creating reconciliation_batches table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.reconciliation_batches (\n",
    "      batch_id STRING,\n",
    "      reconciliation_date TIMESTAMP,\n",
    "      source_systems ARRAY<STRING>,\n",
    "      start_date TIMESTAMP,\n",
    "      end_date TIMESTAMP,\n",
    "      status STRING,\n",
    "      total_transactions BIGINT,\n",
    "      matched_count BIGINT,\n",
    "      unmatched_count BIGINT,\n",
    "      created_at TIMESTAMP,\n",
    "      completed_at TIMESTAMP\n",
    "    )\n",
    "    USING iceberg\n",
    "    \"\"\")\n",
    "    print(\"✓ Created table: lakekeeper.banking.reconciliation_batches\")\n",
    "    print(\"  - Partitioned by: None (small lookup table)\")\n",
    "    print(\"  - Purpose: Track reconciliation batch metadata\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error creating reconciliation_batches table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Tables and Audit Setup\n",
    "\n",
    "**Purpose**: Validate that all tables were created correctly in MinIO and examine the Iceberg file structure.\n",
    "\n",
    "### **What We'll Verify**:\n",
    "1. **Table Existence**: Confirm all tables are created in the `minio.banking` namespace\n",
    "2. **File Structure**: Examine Iceberg metadata and data directories in S3\n",
    "3. **Schema Validation**: Check table schemas are correct\n",
    "4. **Accessibility**: Test basic queries on each table\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Lakekeeper Carefully\n",
    " ![Tables in Lakekeeper](images/tables-in-lakekeeper.png)\n",
    " \n",
    " ![Table Properties in Lakekeeper](images/tables-in-lakekeeper-properties.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📋 Verifying created tables<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "📋 Verifying created tables\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  banking| source_transactions|      false|\n",
      "|  banking|reconciliation_re...|      false|\n",
      "|  banking|reconciliation_ba...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "📊 Table Summary:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "📊 Table Summary:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Total tables in banking namespace: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Total tables in banking namespace: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Expected tables: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Expected tables: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Status: ✓ PASS\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Status: ✓ PASS\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List tables to verify\n",
    "print(\"📋 Verifying created tables...\")\n",
    "tables_df = spark.sql(\"SHOW TABLES IN lakekeeper.banking\")\n",
    "tables_df.show()\n",
    "\n",
    "# Count tables\n",
    "table_count = tables_df.count()\n",
    "print(f\"\\n📊 Table Summary:\")\n",
    "print(f\"- Total tables in banking namespace: {table_count}\")\n",
    "print(f\"- Expected tables: 3\")\n",
    "print(f\"- Status: {'✓ PASS' if table_count >= 3 else '✗ FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Examine Iceberg File Structure in MinIO\n",
    "\n",
    "**Purpose**: Understand how Iceberg organizes files and metadata in your MinIO S3 bucket.\n",
    "\n",
    "### **Iceberg File Organization in S3**:\n",
    "\n",
    "Each Iceberg table creates this structure in your MinIO bucket:\n",
    "```\n",
    "s3a://warehouse/banking/table_name/\n",
    "├── metadata/              # Table metadata and version history\n",
    "│   ├── v1.metadata.json  # Current table schema and properties\n",
    "│   ├── version-hint.text # Points to latest metadata version\n",
    "│   └── .*.crc           # Checksums for data integrity\n",
    "├── data/                # Actual data files (Parquet format)\n",
    "│   └── partition_paths/ # Partitioned data organized by partition keys\n",
    "└── snapshots/           # Table snapshots for time travel\n",
    "```\n",
    "> Use the MinIO Console (http://localhost:9001) or mc CLI to browse and inspect these files.\n",
    "\n",
    "### **Key Files Explained**:\n",
    "- **v1.metadata.json**: Contains table schema, partitioning, and properties\n",
    "- **version-hint.text**: Points to the current metadata version\n",
    "- **.crc files**: Checksums to ensure data integrity\n",
    "- **data/**: Contains actual Parquet files with the data\n",
    "- **snapshots/**: Enables time travel and rollback capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
