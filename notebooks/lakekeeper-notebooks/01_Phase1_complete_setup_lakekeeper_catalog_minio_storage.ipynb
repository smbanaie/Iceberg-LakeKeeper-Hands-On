{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course! Here is the rewritten version of the **first markdown cell** in English, tailored to your actual setup (Lakekeeper as the catalog, MinIO for storage, Postgres for metadata):\n",
    "\n",
    "---\n",
    "\n",
    "# Complete Banking Reconciliation Setup â€“ Phase 1  \n",
    "## Lakekeeper Catalog with MinIO S3 Storage and Postgres Metadata Management\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "This notebook demonstrates how to set up Apache Iceberg using **Lakekeeper** as the catalog (with Postgres as the metadata backend) and **MinIO** as S3-compatible storage for a banking reconciliation system.\n",
    "\n",
    "### **Apache Iceberg Fundamentals**\n",
    "- **Catalog**: Learn how Iceberg works with Lakekeeper (Postgres) and MinIO\n",
    "- **MinIO Storage**: Understand how Iceberg stores data and metadata in MinIO buckets\n",
    "- **Table Structure**: Explore the file and folder organization created by Iceberg tables in MinIO\n",
    "- **Partitioning**: See how Iceberg manages partitioned tables\n",
    "\n",
    "### **What You Will Build**\n",
    "- A complete banking reconciliation system with three core tables\n",
    "- S3-based storage using MinIO\n",
    "- Partitioned tables for efficient querying\n",
    "- Full audit trail and validation\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "#### **1. Iceberg Catalog with Lakekeeper and MinIO**\n",
    "In this setup, the Iceberg catalog is of type REST, managed by Lakekeeper, and data is stored in MinIO:\n",
    "```python\n",
    "spark.sql.catalog.lakekeeper.type = \"rest\"\n",
    "spark.sql.catalog.lakekeeper.uri = \"http://lakekeeper:8181/catalog\"\n",
    "spark.sql.catalog.lakekeeper.warehouse = \"irisa-ot\"\n",
    "```\n",
    "- **Catalog**: A namespace for tables and schemas\n",
    "- **MinIO**: S3-compatible object storage for all table data and metadata\n",
    "- **Warehouse**: The root location in MinIO where data and metadata are stored\n",
    "\n",
    "\n",
    "#### **2. Partitioning Strategy**\n",
    "- **source_transactions**: Partitioned by `days(transaction_date)` and `source_system`\n",
    "- **reconciliation_results**: Partitioned by `days(reconciliation_timestamp)` and `match_status`\n",
    "- **reconciliation_batches**: No partitioning (small lookup table)\n",
    "\n",
    "## Phase 1: Foundation Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the **second markdown cell** rewritten in English and tailored to your setup:\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Import Required Libraries\n",
    "\n",
    "**Purpose:**  \n",
    "Import all necessary libraries for working with Spark, MinIO, and file operations.\n",
    "\n",
    "**Key Libraries:**\n",
    "- `pyspark.sql.SparkSession`: Core Spark functionality\n",
    "- `boto3`: AWS S3/MinIO client for object storage\n",
    "- `os`, `json`, `datetime`: Utilities for file and data manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Spark Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> - Spark Minor Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span> - Iceberg Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.9</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Spark Version: \u001b[1;36m3.5\u001b[0m.\u001b[1;36m6\u001b[0m - Spark Minor Version: \u001b[1;36m3.5\u001b[0m - Iceberg Version: \u001b[1;36m1.9\u001b[0m.\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "!pip install --root-user-action=ignore rich --quiet\n",
    "from rich import print\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# This CATALOG_URL works for the \"docker compose\" testing and development environment\n",
    "# Change 'lakekeeper' if you are not running on \"docker compose\" (f. ex. 'localhost' if Lakekeeper is running locally).\n",
    "CATALOG_URL = \"http://lakekeeper:8181/catalog\"\n",
    "WAREHOUSE = \"irisa-ot\" # as is in lakekeeper : http://localhost:8181/ui/warehouse\n",
    "\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.9.2\"\n",
    "\n",
    "print(f\"Spark Version: {SPARK_VERSION} - Spark Minor Version: {SPARK_MINOR_VERSION} - Iceberg Version: {ICEBERG_VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Stop any existing Spark session\n",
    "\n",
    "**Purpose**: Ensure a clean Spark environment by stopping any existing sessions.\n",
    "\n",
    "**Why This Matters**:\n",
    "- Prevents configuration conflicts\n",
    "- Ensures fresh Iceberg catalog initialization\n",
    "- Clears any cached metadata or connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/22 09:44:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/22 09:44:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/07/22 09:44:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Stopped existing Spark session\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Stopped existing Spark session\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stop any existing Spark session\n",
    "try:\n",
    "    SparkSession.builder.getOrCreate().stop()\n",
    "    print(\"âœ“ Stopped existing Spark session\")\n",
    "except:\n",
    "    print(\"â„¹ No existing Spark session to stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Spark Session with Iceberg + MinIO (S3) Configuration\n",
    "\n",
    "**Purpose:**  \n",
    "Initialize Spark with Apache Iceberg extensions and MinIO S3-compatible catalog configuration.\n",
    "\n",
    "### **Configuration Breakdown:**\n",
    "\n",
    "#### **Iceberg Extensions**\n",
    "```python\n",
    "spark.sql.extensions = \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\n",
    "```\n",
    "- Enables Iceberg-specific SQL commands (CREATE TABLE, MERGE, etc.)\n",
    "- Provides time travel, schema evolution, and partition evolution capabilities\n",
    "\n",
    "#### **Catalog Configuration**\n",
    "```python\n",
    "spark.sql.catalog.lakekeeper = \"org.apache.iceberg.spark.SparkCatalog\"\n",
    "spark.sql.catalog.lakekeeper.type = \"rest\"\n",
    "spark.sql.catalog.lakekeeper.uri = \"http://lakekeeper:8181/catalog\"\n",
    "spark.sql.catalog.lakekeeper.warehouse = \"irisa-ot\"\n",
    "```\n",
    "- **lakekeeper**: The custom catalog name for Lakekeeper REST API\n",
    "- **warehouse**: The MinIO bucket path for table data and metadata\n",
    "\n",
    "#### **Default Catalog**\n",
    "- You will use `lakekeeper` as the catalog name in all SQL operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 09:44:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/07/22 09:44:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Spark session created successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Spark session created successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Spark version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Spark version: \u001b[1;36m3.5\u001b[0m.\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Default catalog: lakekeeper\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Default catalog: lakekeeper\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create warehouse directory if it doesn't exist\n",
    "config = {\n",
    "    f\"spark.sql.catalog.lakekeeper\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    f\"spark.sql.catalog.lakekeeper.type\": \"rest\",\n",
    "    f\"spark.sql.catalog.lakekeeper.uri\": CATALOG_URL,\n",
    "    f\"spark.sql.catalog.lakekeeper.warehouse\": WAREHOUSE,\n",
    "    f\"spark.sql.catalog.lakekeeper.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.defaultCatalog\": \"lakekeeper\",\n",
    "    \"spark.executor.memory\": \"1024m\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.jars.packages\": f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION}\",\n",
    "}\n",
    "\n",
    "spark_config = SparkConf().setMaster('spark://spark-master:7077').setAppName(\"Iceberg-REST-Cluster-Banking-Sample-Phase1\")\n",
    "for k, v in config.items():\n",
    "    spark_config = spark_config.set(k, v)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_config).getOrCreate()\n",
    "\n",
    "spark.sql(\"USE lakekeeper\")\n",
    "print(\"âœ“ Spark session created successfully\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Default catalog: {spark.conf.get('spark.sql.defaultCatalog')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize MinIO Client and Check Health\n",
    "\n",
    "**Purpose:**  \n",
    "Set up MinIO (S3-compatible object storage) for future data operations.\n",
    "\n",
    "### **MinIO Configuration:**\n",
    "- **Endpoint:** `http://minio:9000` (Docker service name)\n",
    "- **Credentials:** `minio`/`minio123` (default development credentials)\n",
    "- **Region:** `us-east-1` (standard region)\n",
    "- **Signature Version:** `s3v4` (AWS Signature Version 4)\n",
    "\n",
    "### **Health Check Strategy:**\n",
    "- Retry logic with exponential backoff\n",
    "- Graceful handling of connection failures\n",
    "- Detailed logging for troubleshooting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7da324818740>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/boto3/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7da323168e90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/boto3/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7da32316a150>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/boto3/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7da32316a360>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/boto3/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7da32316a570>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/boto3/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement boto3 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for boto3\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mboto3\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbotocore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize MinIO client\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "# Initialize MinIO client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minio-root-user',\n",
    "    aws_secret_access_key='minio-root-password',\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "print(\"âœ“ MinIO client initialized\")\n",
    "print(f\"Endpoint: http://minio:9000\")\n",
    "print(f\"Signature Version: s3v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Checking MinIO health<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Checking MinIO health\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ MinIO is ready! Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> existing buckets\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ MinIO is ready! Found \u001b[1;36m1\u001b[0m existing buckets\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check MinIO health with retries\n",
    "print(\"Checking MinIO health...\")\n",
    "max_attempts = 30\n",
    "attempt = 1\n",
    "\n",
    "while attempt <= max_attempts:\n",
    "    try:\n",
    "        # Try to list buckets to check connectivity\n",
    "        buckets = s3_client.list_buckets()\n",
    "        print(f\"âœ“ MinIO is ready! Found {len(buckets['Buckets'])} existing buckets\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Waiting for MinIO... (attempt {attempt}/{max_attempts}): {str(e)}\")\n",
    "        if attempt >= max_attempts:\n",
    "            print(\"âš  MinIO failed to start within the expected time. Continuing anyway...\")\n",
    "            break\n",
    "        time.sleep(2)\n",
    "        attempt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Banking Namespace\n",
    "\n",
    "**Purpose**: Create a logical namespace to organize related tables in MinIO.\n",
    "\n",
    "### **Namespace Benefits**:\n",
    "- **Organization**: Groups related tables together\n",
    "- **Access Control**: Apply permissions at namespace level\n",
    "- **Naming**: Avoid table name conflicts\n",
    "- **Discovery**: Easier to find related tables\n",
    "\n",
    "### **S3 Impact**:\n",
    "The namespace creates a directory structure in your MinIO bucket:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Created namespace: lakekeeper.banking\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Created namespace: lakekeeper.banking\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Namespace location: lakekeeper/banking\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Namespace location: lakekeeper/banking\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the banking namespace\n",
    "try:\n",
    "    spark.sql(\"CREATE NAMESPACE IF NOT EXISTS lakekeeper.banking\")\n",
    "    print(\"âœ“ Created namespace: lakekeeper.banking\")\n",
    "    print(f\"Namespace location: lakekeeper/banking\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating namespace: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5b: Verify Namespace Creation \n",
    "\n",
    "**Purpose:**  \n",
    "Confirm that the namespace has been created in the Lakekeeper catalog.\n",
    "\n",
    "> Note: Click on `irisa-ot` at `http://localhost:8181/ui/warehouse` to view the namespace.\n",
    "\n",
    "**Also, check the Lakekeeper Postgres database:** Look at the `namespace` table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the **eighth markdown cell** rewritten in English and tailored to your setup:\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Create Iceberg Tables \n",
    "\n",
    "**Purpose:**  \n",
    "Create the core tables for the banking reconciliation system in Lakekeeper and MinIO.\n",
    "\n",
    "### **Table Design Strategy:**\n",
    "\n",
    "#### **1. source_transactions**\n",
    "- **Purpose:** Store all transaction data from different source systems\n",
    "- **Partitioning:** By `days(transaction_date)` and `source_system`\n",
    "- **Benefits:** Efficient querying by date range and source\n",
    "- **Schema:** Comprehensive transaction metadata\n",
    "\n",
    "#### **2. reconciliation_results**\n",
    "- **Purpose:** Store reconciliation outcomes and discrepancies\n",
    "- **Partitioning:** By `days(reconciliation_timestamp)` and `match_status`\n",
    "- **Benefits:** Easy analysis of reconciliation performance\n",
    "- **Schema:** Detailed discrepancy tracking\n",
    "\n",
    "#### **3. reconciliation_batches**\n",
    "- **Purpose:** Track reconciliation batch metadata\n",
    "- **Partitioning:** None (small lookup table)\n",
    "- **Benefits:** Batch-level monitoring and reporting\n",
    "- **Schema:** Batch execution metadata\n",
    "\n",
    "> All tables will be created under the `lakekeeper.banking` namespace and stored in your MinIO S3 bucket.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating source_transactions table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating source_transactions table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Created table: lakekeeper.banking.source_transactions\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Created table: lakekeeper.banking.source_transactions\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">days</span><span style=\"font-weight: bold\">(</span>transaction_date<span style=\"font-weight: bold\">)</span>, source_system\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[1;35mdays\u001b[0m\u001b[1m(\u001b[0mtransaction_date\u001b[1m)\u001b[0m, source_system\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Store all transaction data from different sources\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Store all transaction data from different sources\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create source_transactions table\n",
    "print(\"Creating source_transactions table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.source_transactions (\n",
    "      transaction_id STRING,\n",
    "      source_system STRING,\n",
    "      transaction_date TIMESTAMP,\n",
    "      amount DECIMAL(18,2),\n",
    "      account_id STRING,\n",
    "      transaction_type STRING,\n",
    "      reference_id STRING,\n",
    "      status STRING,\n",
    "      payload STRING,\n",
    "      created_at TIMESTAMP,\n",
    "      processing_timestamp TIMESTAMP\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (days(transaction_date), source_system)\n",
    "    \"\"\")\n",
    "    print(\"âœ“ Created table: lakekeeper.banking.source_transactions\")\n",
    "    print(\"  - Partitioned by: days(transaction_date), source_system\")\n",
    "    print(\"  - Purpose: Store all transaction data from different sources\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating source_transactions table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating reconciliation_results table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating reconciliation_results table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Created table: lakekeeper.banking.reconciliation_results\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Created table: lakekeeper.banking.reconciliation_results\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">days</span><span style=\"font-weight: bold\">(</span>reconciliation_timestamp<span style=\"font-weight: bold\">)</span>, match_status\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[1;35mdays\u001b[0m\u001b[1m(\u001b[0mreconciliation_timestamp\u001b[1m)\u001b[0m, match_status\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Store reconciliation outcomes and discrepancies\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Store reconciliation outcomes and discrepancies\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create reconciliation_results table\n",
    "print(\"Creating reconciliation_results table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.reconciliation_results (\n",
    "      reconciliation_id STRING,\n",
    "      batch_id STRING,\n",
    "      primary_transaction_id STRING,\n",
    "      secondary_transaction_id STRING,\n",
    "      match_status STRING,\n",
    "      discrepancy_type STRING,\n",
    "      discrepancy_amount DECIMAL(18,2),\n",
    "      reconciliation_timestamp TIMESTAMP,\n",
    "      notes STRING\n",
    "    )\n",
    "    USING iceberg\n",
    "    PARTITIONED BY (days(reconciliation_timestamp), match_status)\n",
    "    \"\"\")\n",
    "    print(\"âœ“ Created table: lakekeeper.banking.reconciliation_results\")\n",
    "    print(\"  - Partitioned by: days(reconciliation_timestamp), match_status\")\n",
    "    print(\"  - Purpose: Store reconciliation outcomes and discrepancies\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating reconciliation_results table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Creating reconciliation_batches table<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Creating reconciliation_batches table\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ“ Created table: lakekeeper.banking.reconciliation_batches\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ“ Created table: lakekeeper.banking.reconciliation_batches\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Partitioned by: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> <span style=\"font-weight: bold\">(</span>small lookup table<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Partitioned by: \u001b[3;35mNone\u001b[0m \u001b[1m(\u001b[0msmall lookup table\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - Purpose: Track reconciliation batch metadata\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - Purpose: Track reconciliation batch metadata\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create reconciliation_batches table\n",
    "print(\"Creating reconciliation_batches table...\")\n",
    "try:\n",
    "    spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS lakekeeper.banking.reconciliation_batches (\n",
    "      batch_id STRING,\n",
    "      reconciliation_date TIMESTAMP,\n",
    "      source_systems ARRAY<STRING>,\n",
    "      start_date TIMESTAMP,\n",
    "      end_date TIMESTAMP,\n",
    "      status STRING,\n",
    "      total_transactions BIGINT,\n",
    "      matched_count BIGINT,\n",
    "      unmatched_count BIGINT,\n",
    "      created_at TIMESTAMP,\n",
    "      completed_at TIMESTAMP\n",
    "    )\n",
    "    USING iceberg\n",
    "    \"\"\")\n",
    "    print(\"âœ“ Created table: lakekeeper.banking.reconciliation_batches\")\n",
    "    print(\"  - Partitioned by: None (small lookup table)\")\n",
    "    print(\"  - Purpose: Track reconciliation batch metadata\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating reconciliation_batches table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Verify Tables and Audit Setup\n",
    "\n",
    "**Purpose**: Validate that all tables were created correctly in MinIO and examine the Iceberg file structure.\n",
    "\n",
    "### **What We'll Verify**:\n",
    "1. **Table Existence**: Confirm all tables are created in the `minio.banking` namespace\n",
    "2. **File Structure**: Examine Iceberg metadata and data directories in S3\n",
    "3. **Schema Validation**: Check table schemas are correct\n",
    "4. **Accessibility**: Test basic queries on each table\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Lakekeeper Carefully\n",
    " ![Tables in Lakekeeper](images/tables-in-lakekeeper.png)\n",
    " \n",
    " ![Table Properties in Lakekeeper](images/tables-in-lakekeeper-properties.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ðŸ“‹ Verifying created tables<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ðŸ“‹ Verifying created tables\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  banking| source_transactions|      false|\n",
      "|  banking|reconciliation_re...|      false|\n",
      "|  banking|reconciliation_ba...|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "ðŸ“Š Table Summary:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "ðŸ“Š Table Summary:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Total tables in banking namespace: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Total tables in banking namespace: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Expected tables: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Expected tables: \u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">- Status: âœ“ PASS\n",
       "</pre>\n"
      ],
      "text/plain": [
       "- Status: âœ“ PASS\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List tables to verify\n",
    "print(\"ðŸ“‹ Verifying created tables...\")\n",
    "tables_df = spark.sql(\"SHOW TABLES IN lakekeeper.banking\")\n",
    "tables_df.show()\n",
    "\n",
    "# Count tables\n",
    "table_count = tables_df.count()\n",
    "print(f\"\\nðŸ“Š Table Summary:\")\n",
    "print(f\"- Total tables in banking namespace: {table_count}\")\n",
    "print(f\"- Expected tables: 3\")\n",
    "print(f\"- Status: {'âœ“ PASS' if table_count >= 3 else 'âœ— FAIL'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here is a **conclusion markdown cell** tailored to your setup:\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, you have successfully set up a foundational lakehouse architecture for banking reconciliation using Apache Iceberg, Lakekeeper as the catalog (with Postgres for metadata management), and MinIO as S3-compatible storage. You learned how to:\n",
    "\n",
    "- Configure Spark to work with Iceberg, Lakekeeper, and MinIO\n",
    "- Initialize and verify the health of your MinIO storage\n",
    "- Create a logical namespace for organizing your banking tables\n",
    "- Design and create partitioned Iceberg tables for efficient data management and querying\n",
    "- Validate the setup by checking table existence and file structures in both Lakekeeper and MinIO\n",
    "\n",
    "This setup provides a robust, scalable, and auditable foundation for advanced analytics and reconciliation workflows in a modern data lakehouse environment.\n",
    "\n",
    "You can now proceed to ingest data, perform reconciliation logic, and explore advanced Iceberg features such as time travel, schema evolution, and more.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
