{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# This CATALOG_URL and MANAGEMENT_URL work for the \"docker compose\" testing and development environment.\n",
    "# Change 'lakekeeper' if you are not running on \"docker compose\" (f. ex. 'localhost' if Lakekeeper is running locally).\n",
    "CATALOG_URL = \"http://lakekeeper:8181/catalog\"\n",
    "MANAGEMENT_URL = \"http://lakekeeper:8181/management\"\n",
    "\n",
    "WAREHOUSE = \"new_warehouse\"\n",
    "CATALOG = \"demo_catalog\"\n",
    "NAMESPACE = \"demo_namespace\"\n",
    "\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.9.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m response = requests.post(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMANAGEMENT_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/v1/warehouse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      2\u001b[39m               json={\n\u001b[32m      3\u001b[39m                 \u001b[38;5;66;03m# Name of the new warehouse\u001b[39;00m\n\u001b[32m      4\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mwarehouse-name\u001b[39m\u001b[33m\"\u001b[39m: WAREHOUSE,\n\u001b[32m      5\u001b[39m                 \u001b[38;5;66;03m# Physical location of this warehouse\u001b[39;00m\n\u001b[32m      6\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstorage-profile\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      7\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33ms3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mbucket\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mnew_warehouse\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mflavor\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mminio\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;66;03m# For AWS Warhouses, use flavor \"aws\"\u001b[39;00m\n\u001b[32m     10\u001b[39m                     \u001b[38;5;66;03m# you can change the prefix to something else, f. ex. f\"{WAREHOUSE}\u001b[39;00m\n\u001b[32m     11\u001b[39m                     \u001b[38;5;66;03m# as long as it is unique in the bucket\u001b[39;00m\n\u001b[32m     12\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mkey-prefix\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mspark\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33massume-role-arn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[32m     14\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mendpoint\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mhttp://minio:9000\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mregion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mlocal-01\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mpath-style-access\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     17\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33msts-enabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     18\u001b[39m                 },\n\u001b[32m     19\u001b[39m                 \u001b[38;5;66;03m# Storage Credentials for the profile specified above.\u001b[39;00m\n\u001b[32m     20\u001b[39m                 \u001b[38;5;66;03m# These credentials are used to grant clients access to specific files in the storage.\u001b[39;00m\n\u001b[32m     21\u001b[39m                 \u001b[38;5;66;03m# Clients do not need to know those credentials and will never obtain them directly.\u001b[39;00m\n\u001b[32m     22\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstorage-credential\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     23\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33ms3\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mcredential-type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33maccess-key\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33maws-access-key-id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mminio-root-user\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33maws-secret-access-key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mminio-root-password\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m                 }\n\u001b[32m     28\u001b[39m             })\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{MANAGEMENT_URL}/v1/warehouse\",\n",
    "              json={\n",
    "                # Name of the new warehouse\n",
    "                \"warehouse-name\": WAREHOUSE,\n",
    "                # Physical location of this warehouse\n",
    "                \"storage-profile\": {\n",
    "                    \"type\": \"s3\",\n",
    "                    \"bucket\": \"new_warehouse\",\n",
    "                    \"flavor\": \"minio\", # For AWS Warhouses, use flavor \"aws\"\n",
    "                    # you can change the prefix to something else, f. ex. f\"{WAREHOUSE}\n",
    "                    # as long as it is unique in the bucket\n",
    "                    \"key-prefix\": \"spark\",\n",
    "                    \"assume-role-arn\": null,\n",
    "                    \"endpoint\": \"http://minio:9000\",\n",
    "                    \"region\": \"local-01\",\n",
    "                    \"path-style-access\": True,\n",
    "                    \"sts-enabled\": True\n",
    "                },\n",
    "                # Storage Credentials for the profile specified above.\n",
    "                # These credentials are used to grant clients access to specific files in the storage.\n",
    "                # Clients do not need to know those credentials and will never obtain them directly.\n",
    "                \"storage-credential\": {\n",
    "                    \"type\": \"s3\",\n",
    "                    \"credential-type\": \"access-key\",\n",
    "                    \"aws-access-key-id\": \"minio-root-user\",\n",
    "                    \"aws-secret-access-key\": \"minio-root-password\"\n",
    "                }\n",
    "            })\n",
    "print(f\"{response.status_code}: {response.reason}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As warehouse names must be unique inside a project, creating the same warehouse again would fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    f\"spark.sql.catalog.{CATALOG}\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    f\"spark.sql.catalog.{CATALOG}.type\": \"rest\",\n",
    "    f\"spark.sql.catalog.{CATALOG}.uri\": CATALOG_URL,\n",
    "    f\"spark.sql.catalog.{CATALOG}.warehouse\": f\"{WAREHOUSE}\",\n",
    "    f\"spark.sql.catalog.{CATALOG}.io-impl\": \"org.apache.iceberg.aws.s3.S3FileIO\",\n",
    "    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    f\"spark.sql.defaultCatalog\": CATALOG,\n",
    "    \"spark.jars.packages\": f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_config = SparkConf().setMaster('local').setAppName(\"Iceberg-REST\")\n",
    "for k, v in config.items():\n",
    "    spark_config = spark_config.set(k, v)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_config).getOrCreate()\n",
    "\n",
    "spark.sql(f\"USE {CATALOG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {NAMESPACE}\")\n",
    "spark.sql(\"SHOW NAMESPACES\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[1, 'a-string', 2.2]], columns=['id', 'strings', 'floats'])\n",
    "sdf = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.writeTo(f\"{NAMESPACE}.my_table\").createOrReplace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT * FROM {NAMESPACE}.my_table\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
