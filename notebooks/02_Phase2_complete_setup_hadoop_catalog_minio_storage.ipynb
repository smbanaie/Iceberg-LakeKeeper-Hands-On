{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Banking Reconciliation Setup - Phase 2\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "This notebook demonstrates how to generate and populate data into Apache Iceberg tables using a **local catalog**. You will learn:\n",
    "\n",
    "### **Data Generation Fundamentals**\n",
    "- **Realistic Data Creation**: Generate banking transactions that mimic real-world scenarios\n",
    "- **Multi-System Simulation**: Create data from different source systems (core banking, card processor, payment gateway)\n",
    "- **Discrepancy Introduction**: Intentionally create mismatches to test reconciliation logic\n",
    "- **Data Quality**: Ensure generated data meets business requirements\n",
    "\n",
    "### **Data Ingestion with Iceberg**\n",
    "- **CSV to Iceberg**: Convert CSV files to Iceberg table format\n",
    "- **Partitioning Strategy**: How data is organized by date and source system\n",
    "- **Metadata Management**: Understanding how Iceberg tracks data lineage\n",
    "- **Incremental Loading**: Add new data without affecting existing records\n",
    "\n",
    "### **Audit and Validation**\n",
    "- **Data Quality Checks**: Verify data integrity and completeness\n",
    "- **Performance Analysis**: Monitor query performance with real data\n",
    "- **File Structure Analysis**: Examine how Iceberg organizes data files\n",
    "- **Reconciliation Readiness**: Ensure data is ready for reconciliation processes\n",
    "\n",
    "## Phase 2: Data Generation and Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries and Setup\n",
    "\n",
    "**Purpose**: Import all necessary libraries for data generation, manipulation, and Iceberg operations.\n",
    "\n",
    "### **Key Libraries**:\n",
    "- `pyspark.sql`: Spark DataFrame operations and Iceberg integration\n",
    "- `pandas`: Data manipulation and CSV handling\n",
    "- `faker`: Generate realistic fake data\n",
    "- `uuid`, `random`, `datetime`: Data generation utilities\n",
    "- `json`: Handle complex payload structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì All required libraries imported successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì All required libraries imported successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Faker locale: <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">bound</span><span style=\"color: #000000; text-decoration-color: #000000\"> method BaseProvider.locale of &lt;faker.providers.user_agent.Provider object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7b79f1cbe900</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Faker locale: \u001b[1m<\u001b[0m\u001b[1;95mbound\u001b[0m\u001b[39m method BaseProvider.locale of <faker.providers.user_agent.Provider object at \u001b[0m\u001b[1;36m0x7b79f1cbe900\u001b[0m\u001b[39m>\u001b[0m\u001b[1m>\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Current timestamp: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:25:43</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">683491</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Current timestamp: \u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m22\u001b[0m \u001b[1;92m08:25:43\u001b[0m.\u001b[1;36m683491\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install --root-user-action=ignore rich faker boto3 --quiet\n",
    "from rich import print\n",
    "# Import required libraries for data generation and manipulation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when, lit, current_timestamp\n",
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker for realistic data generation\n",
    "fake = Faker()\n",
    "\n",
    "print(\"‚úì All required libraries imported successfully\")\n",
    "print(f\"Faker locale: {fake.locale}\")\n",
    "print(f\"Current timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Spark Session with Iceberg Configuration\n",
    "\n",
    "**Purpose**: Initialize Spark with the same Iceberg configuration from Phase 1.\n",
    "\n",
    "### **Configuration Consistency**:\n",
    "- Uses the same local catalog configuration\n",
    "- Maintains warehouse directory structure\n",
    "- Ensures compatibility with existing tables\n",
    "\n",
    "### **Why This Matters**:\n",
    "- **Session Continuity**: Same configuration as Phase 1\n",
    "- **Table Access**: Can access previously created tables\n",
    "- **Data Consistency**: Ensures data is written to correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì Warehouse directory: s3a:<span style=\"color: #800080; text-decoration-color: #800080\">//</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">warehouse</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì Warehouse directory: s3a:\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m\u001b[95mwarehouse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì Stopped existing Spark session\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì Stopped existing Spark session\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì Spark session created successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì Spark session created successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Spark version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Spark version: \u001b[1;36m3.5\u001b[0m.\u001b[1;36m6\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Default catalog: local\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Default catalog: local\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Warehouse location: s3a:<span style=\"color: #800080; text-decoration-color: #800080\">//</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">warehouse</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Warehouse location: s3a:\u001b[35m/\u001b[0m\u001b[35m/\u001b[0m\u001b[95mwarehouse\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "import pyspark\n",
    "\n",
    "# ŸÜÿ≥ÿÆŸá‚ÄåŸáÿß€å ŸÖŸàÿ±ÿØ ŸÜ€åÿßÿ≤\n",
    "SPARK_VERSION = pyspark.__version__\n",
    "SPARK_MINOR_VERSION = '.'.join(SPARK_VERSION.split('.')[:2])\n",
    "ICEBERG_VERSION = \"1.9.2\"\n",
    "\n",
    "# ŸÖÿ≥€åÿ± warehouse ÿ±Ÿà€å MinIO\n",
    "warehouse_dir = \"s3a://warehouse\"\n",
    "print(f\"‚úì Warehouse directory: {warehouse_dir}\")\n",
    "\n",
    "# ÿ™ŸàŸÇŸÅ ÿ≥ÿ¥ŸÜ ŸÇÿ®ŸÑ€å ÿØÿ± ÿµŸàÿ±ÿ™ Ÿàÿ¨ŸàÿØ\n",
    "try:\n",
    "    SparkSession.builder.getOrCreate().stop()\n",
    "    print(\"‚úì Stopped existing Spark session\")\n",
    "except:\n",
    "    print(\"‚Ñπ No existing Spark session to stop\")\n",
    "\n",
    "# ÿ™ŸÜÿ∏€åŸÖÿßÿ™ ÿßÿ≥Ÿæÿßÿ±⁄© Ÿà ÿ¢€åÿ≥ÿ®ÿ±⁄Ø ÿ®ÿ±ÿß€å MinIO\n",
    "config = {\n",
    "    \"spark.sql.extensions\": \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "    \"spark.sql.catalog.minio\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.minio.type\": \"hadoop\",\n",
    "    \"spark.sql.catalog.minio.warehouse\": warehouse_dir,\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": \"http://minio:9000\",\n",
    "    \"spark.hadoop.fs.s3a.access.key\": \"minio\",\n",
    "    \"spark.hadoop.fs.s3a.secret.key\": \"minio123\",\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": \"true\",\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\",\n",
    "    \"spark.executor.memory\": \"1024m\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.jars.packages\": f\"org.apache.iceberg:iceberg-spark-runtime-{SPARK_MINOR_VERSION}_2.12:{ICEBERG_VERSION},org.apache.hadoop:hadoop-aws:3.3.2\",\n",
    "}\n",
    "\n",
    "spark_config = SparkConf().setMaster(\"spark://spark-master:7077\").setAppName(\"Iceberg on MinIO - Phase2 - Data Generation\")\n",
    "for k, v in config.items():\n",
    "    spark_config = spark_config.set(k, v)\n",
    "\n",
    "spark = SparkSession.builder.config(conf=spark_config).getOrCreate()\n",
    "\n",
    "print(\"‚úì Spark session created successfully\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Default catalog: {spark.conf.get('spark.sql.defaultCatalog')}\")\n",
    "print(f\"Warehouse location: {spark.conf.get('spark.sql.catalog.minio.warehouse')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Existing Tables and Data\n",
    "\n",
    "**Purpose**: Confirm that tables from Phase 1 exist and are accessible.\n",
    "\n",
    "### **What We'll Check**:\n",
    "1. **Table Existence**: Verify all three tables are present\n",
    "2. **Schema Validation**: Confirm table schemas are correct\n",
    "3. **Current Data State**: Check if any data already exists\n",
    "4. **Partitioning**: Verify partitioning strategy is in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Verifying existing tables from Phase <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Verifying existing tables from Phase \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Available tables:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Available tables:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|  banking|reconciliation_ba...|      false|\n",
      "|  banking|reconciliation_re...|      false|\n",
      "|  banking| source_transactions|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üìä Current data counts:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üìä Current data counts:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/22 08:27:52 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:28:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:28:22 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:28:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:28:51 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:29:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "25/07/22 08:29:22 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì minio.banking.source_transactions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> rows\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì minio.banking.source_transactions: \u001b[1;36m0\u001b[0m rows\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì minio.banking.reconciliation_results: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> rows\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì minio.banking.reconciliation_results: \u001b[1;36m0\u001b[0m rows\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì minio.banking.reconciliation_batches: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> rows\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì minio.banking.reconciliation_batches: \u001b[1;36m0\u001b[0m rows\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Table schemas:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Table schemas:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üìã minio.banking.source_transactions schema:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üìã minio.banking.source_transactions schema:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|      transaction_id|              string|   NULL|\n",
      "|       source_system|              string|   NULL|\n",
      "|    transaction_date|           timestamp|   NULL|\n",
      "|              amount|       decimal(18,2)|   NULL|\n",
      "|          account_id|              string|   NULL|\n",
      "|    transaction_type|              string|   NULL|\n",
      "|        reference_id|              string|   NULL|\n",
      "|              status|              string|   NULL|\n",
      "|             payload|              string|   NULL|\n",
      "|          created_at|           timestamp|   NULL|\n",
      "|processing_timestamp|           timestamp|   NULL|\n",
      "|                    |                    |       |\n",
      "|      # Partitioning|                    |       |\n",
      "|              Part 0|days(transaction_...|       |\n",
      "|              Part 1|       source_system|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üìã minio.banking.reconciliation_results schema:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üìã minio.banking.reconciliation_results schema:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|   reconciliation_id|              string|   NULL|\n",
      "|            batch_id|              string|   NULL|\n",
      "|primary_transacti...|              string|   NULL|\n",
      "|secondary_transac...|              string|   NULL|\n",
      "|        match_status|              string|   NULL|\n",
      "|    discrepancy_type|              string|   NULL|\n",
      "|  discrepancy_amount|       decimal(18,2)|   NULL|\n",
      "|reconciliation_ti...|           timestamp|   NULL|\n",
      "|               notes|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|      # Partitioning|                    |       |\n",
      "|              Part 0|days(reconciliati...|       |\n",
      "|              Part 1|        match_status|       |\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üìã minio.banking.reconciliation_batches schema:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üìã minio.banking.reconciliation_batches schema:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+-------+\n",
      "|           col_name|    data_type|comment|\n",
      "+-------------------+-------------+-------+\n",
      "|           batch_id|       string|   NULL|\n",
      "|reconciliation_date|    timestamp|   NULL|\n",
      "|     source_systems|array<string>|   NULL|\n",
      "|         start_date|    timestamp|   NULL|\n",
      "|           end_date|    timestamp|   NULL|\n",
      "|             status|       string|   NULL|\n",
      "| total_transactions|       bigint|   NULL|\n",
      "|      matched_count|       bigint|   NULL|\n",
      "|    unmatched_count|       bigint|   NULL|\n",
      "|         created_at|    timestamp|   NULL|\n",
      "|       completed_at|    timestamp|   NULL|\n",
      "+-------------------+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify existing tables from Phase 1\n",
    "print(\" Verifying existing tables from Phase 1...\")\n",
    "\n",
    "# List tables in banking namespace\n",
    "tables_df = spark.sql(\"SHOW TABLES IN minio.banking\")\n",
    "print(\"\\n Available tables:\")\n",
    "tables_df.show()\n",
    "\n",
    "# Check current data counts\n",
    "print(\"\\nüìä Current data counts:\")\n",
    "tables_to_check = [\n",
    "    'minio.banking.source_transactions',\n",
    "    'minio.banking.reconciliation_results',\n",
    "    'minio.banking.reconciliation_batches'\n",
    "]\n",
    "\n",
    "for table in tables_to_check:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as count FROM {table}\").collect()[0]['count']\n",
    "        print(f\"‚úì {table}: {count} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {table}: Error - {str(e)}\")\n",
    "\n",
    "# Verify table schemas\n",
    "print(\"\\n Table schemas:\")\n",
    "for table in tables_to_check:\n",
    "    try:\n",
    "        schema = spark.sql(f\"DESCRIBE {table}\")\n",
    "        print(f\"\\nüìã {table} schema:\")\n",
    "        schema.show()\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error getting schema for {table}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Data Generation Configuration\n",
    "\n",
    "**Purpose**: Set up the configuration for generating realistic banking transaction data.\n",
    "\n",
    "### **Data Generation Strategy**:\n",
    "\n",
    "#### **Source Systems**\n",
    "- **core_banking**: Primary system with complete transaction records\n",
    "- **card_processor**: Secondary system with some discrepancies\n",
    "- **payment_gateway**: Tertiary system with additional discrepancies\n",
    "\n",
    "#### **Transaction Types**\n",
    "- **deposit**: Money added to account\n",
    "- **withdrawal**: Money removed from account\n",
    "- **transfer**: Money moved between accounts\n",
    "- **payment**: Payment to merchant/service\n",
    "- **refund**: Money returned to account\n",
    "- **fee**: Service charges and fees\n",
    "\n",
    "#### **Discrepancy Types**\n",
    "- **amount**: Slight differences in transaction amounts\n",
    "- **date**: Timing differences in transaction dates\n",
    "- **status**: Different transaction statuses\n",
    "- **missing**: Transactions that exist in one system but not another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚öôÔ∏è Setting up data generation configuration<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚öôÔ∏è Setting up data generation configuration\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Source systems: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'core_banking'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'card_processor'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'payment_gateway'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Source systems: \u001b[1m[\u001b[0m\u001b[32m'core_banking'\u001b[0m, \u001b[32m'card_processor'\u001b[0m, \u001b[32m'payment_gateway'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Transaction types: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'deposit'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'withdrawal'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'transfer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'payment'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'refund'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'fee'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Transaction types: \u001b[1m[\u001b[0m\u001b[32m'deposit'\u001b[0m, \u001b[32m'withdrawal'\u001b[0m, \u001b[32m'transfer'\u001b[0m, \u001b[32m'payment'\u001b[0m, \u001b[32m'refund'\u001b[0m, \u001b[32m'fee'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Status values: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'completed'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pending'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'failed'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'reversed'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Status values: \u001b[1m[\u001b[0m\u001b[32m'completed'\u001b[0m, \u001b[32m'pending'\u001b[0m, \u001b[32m'failed'\u001b[0m, \u001b[32m'reversed'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üìä Data generation parameters:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üìä Data generation parameters:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - num_accounts: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - num_accounts: \u001b[1;36m100\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - primary_transactions: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - primary_transactions: \u001b[1;36m5000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - date_range_days: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - date_range_days: \u001b[1;36m30\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - error_rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - error_rate: \u001b[1;36m0.05\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  - extra_transactions_rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  - extra_transactions_rate: \u001b[1;36m0.02\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Date range: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Date range: \u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m22\u001b[0m to \u001b[1;36m2025\u001b[0m-\u001b[1;36m07\u001b[0m-\u001b[1;36m22\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define data generation configuration\n",
    "print(\"‚öôÔ∏è Setting up data generation configuration...\")\n",
    "\n",
    "# Source systems for multi-system reconciliation\n",
    "SOURCE_SYSTEMS = ['core_banking', 'card_processor', 'payment_gateway']\n",
    "print(f\"Source systems: {SOURCE_SYSTEMS}\")\n",
    "\n",
    "# Transaction types for realistic banking scenarios\n",
    "TRANSACTION_TYPES = ['deposit', 'withdrawal', 'transfer', 'payment', 'refund', 'fee']\n",
    "print(f\"Transaction types: {TRANSACTION_TYPES}\")\n",
    "\n",
    "# Transaction statuses\n",
    "STATUS_VALUES = ['completed', 'pending', 'failed', 'reversed']\n",
    "print(f\"Status values: {STATUS_VALUES}\")\n",
    "\n",
    "# Data generation parameters\n",
    "DATA_CONFIG = {\n",
    "    'num_accounts': 100,\n",
    "    'primary_transactions': 5000,\n",
    "    'date_range_days': 30,\n",
    "    'error_rate': 0.05,  # 5% discrepancy rate\n",
    "    'extra_transactions_rate': 0.02  # 2% extra transactions in secondary systems\n",
    "}\n",
    "\n",
    "print(f\"\\nüìä Data generation parameters:\")\n",
    "for key, value in DATA_CONFIG.items():\n",
    "    print(f\"  - {key}: {value}\")\n",
    "\n",
    "# Define date range for transactions\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=DATA_CONFIG['date_range_days'])\n",
    "print(f\"\\n Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Data Generation Functions\n",
    "\n",
    "**Purpose**: Define functions to generate realistic banking transaction data.\n",
    "\n",
    "### **Data Generation Functions**:\n",
    "\n",
    "#### **1. Account ID Generation**\n",
    "- Creates unique account identifiers\n",
    "- Uses consistent format for all systems\n",
    "- Ensures referential integrity\n",
    "\n",
    "#### **2. Transaction ID Generation**\n",
    "- System-specific prefixes (CB, CP, PG)\n",
    "- Unique identifiers for each transaction\n",
    "- Enables cross-system matching\n",
    "\n",
    "#### **3. Transaction Data Generation**\n",
    "- Realistic amounts and dates\n",
    "- Proper status distribution\n",
    "- Rich payload metadata\n",
    "\n",
    "#### **4. Discrepancy Introduction**\n",
    "- Intentional mismatches for testing\n",
    "- Various discrepancy types\n",
    "- Controlled error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üîß Creating data generation functions<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üîß Creating data generation functions\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì Data generation functions created successfully\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì Data generation functions created successfully\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data generation functions\n",
    "print(\"üîß Creating data generation functions...\")\n",
    "\n",
    "def generate_account_ids(num_accounts=100):\n",
    "    \"\"\"Generate a list of random account IDs.\"\"\"\n",
    "    return [f\"ACC{fake.unique.random_number(digits=8)}\" for _ in range(num_accounts)]\n",
    "\n",
    "def generate_transaction_id(source_system):\n",
    "    \"\"\"Generate a transaction ID with a prefix based on the source system.\"\"\"\n",
    "    prefixes = {\n",
    "        'core_banking': 'CB',\n",
    "        'card_processor': 'CP',\n",
    "        'payment_gateway': 'PG'\n",
    "    }\n",
    "    prefix = prefixes.get(source_system, 'TX')\n",
    "    return f\"{prefix}-{uuid.uuid4().hex[:12].upper()}\"\n",
    "\n",
    "def generate_reference_id():\n",
    "    \"\"\"Generate a reference ID for transactions.\"\"\"\n",
    "    return f\"REF-{fake.unique.random_number(digits=10)}\"\n",
    "\n",
    "def generate_transaction_data(source_system, account_ids, start_date, end_date, count=1000):\n",
    "    \"\"\"Generate transaction data for a specific source system.\"\"\"\n",
    "    transactions = []\n",
    "    \n",
    "    for _ in range(count):\n",
    "        # Generate random transaction date within the date range\n",
    "        transaction_date = fake.date_time_between_dates(\n",
    "            datetime_start=start_date,\n",
    "            datetime_end=end_date\n",
    "        )\n",
    "        \n",
    "        # Generate random amount (between $1 and $10,000)\n",
    "        amount = round(random.uniform(1, 10000), 2)\n",
    "        \n",
    "        # Select random account ID\n",
    "        account_id = random.choice(account_ids)\n",
    "        \n",
    "        # Generate transaction ID\n",
    "        transaction_id = generate_transaction_id(source_system)\n",
    "        \n",
    "        # Select random transaction type\n",
    "        transaction_type = random.choice(TRANSACTION_TYPES)\n",
    "        \n",
    "        # Generate reference ID\n",
    "        reference_id = generate_reference_id()\n",
    "        \n",
    "        # Select random status\n",
    "        status = random.choice(STATUS_VALUES)\n",
    "        \n",
    "        # Generate additional payload data\n",
    "        payload = {\n",
    "            'description': fake.sentence(),\n",
    "            'location': fake.city(),\n",
    "            'merchant': fake.company() if transaction_type in ['payment', 'refund'] else None,\n",
    "            'category': fake.word(),\n",
    "            'metadata': {\n",
    "                'device': fake.user_agent(),\n",
    "                'ip_address': fake.ipv4(),\n",
    "                'channel': random.choice(['web', 'mobile', 'atm', 'branch', 'phone'])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Create transaction record\n",
    "        transaction = {\n",
    "            'transaction_id': transaction_id,\n",
    "            'source_system': source_system,\n",
    "            'transaction_date': transaction_date,\n",
    "            'amount': amount,\n",
    "            'account_id': account_id,\n",
    "            'transaction_type': transaction_type,\n",
    "            'reference_id': reference_id,\n",
    "            'status': status,\n",
    "            'payload': json.dumps(payload),\n",
    "            'created_at': transaction_date - timedelta(minutes=random.randint(1, 60)),\n",
    "            'processing_timestamp': transaction_date + timedelta(seconds=random.randint(1, 30))\n",
    "        }\n",
    "        \n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "def create_matching_transactions(primary_transactions, secondary_system, error_rate=0.05):\n",
    "    \"\"\"Create matching transactions for a secondary system with intentional discrepancies.\"\"\"\n",
    "    secondary_transactions = []\n",
    "    \n",
    "    for primary_tx in primary_transactions:\n",
    "        # Create a copy of the primary transaction\n",
    "        secondary_tx = primary_tx.copy()\n",
    "        \n",
    "        # Change the transaction ID and source system\n",
    "        secondary_tx['transaction_id'] = generate_transaction_id(secondary_system)\n",
    "        secondary_tx['source_system'] = secondary_system\n",
    "        \n",
    "        # Introduce discrepancies based on error rate\n",
    "        if random.random() < error_rate:\n",
    "            # Choose a type of discrepancy\n",
    "            discrepancy_type = random.choice(['amount', 'date', 'status', 'missing'])\n",
    "            \n",
    "            if discrepancy_type == 'amount':\n",
    "                # Change the amount slightly\n",
    "                original_amount = secondary_tx['amount']\n",
    "                secondary_tx['amount'] = round(original_amount * random.uniform(0.95, 1.05), 2)\n",
    "                \n",
    "            elif discrepancy_type == 'date':\n",
    "                # Shift the date slightly\n",
    "                original_date = secondary_tx['transaction_date']\n",
    "                secondary_tx['transaction_date'] = original_date + timedelta(\n",
    "                    minutes=random.randint(-120, 120)\n",
    "                )\n",
    "                \n",
    "            elif discrepancy_type == 'status':\n",
    "                # Change the status\n",
    "                original_status = secondary_tx['status']\n",
    "                new_status = random.choice([s for s in STATUS_VALUES if s != original_status])\n",
    "                secondary_tx['status'] = new_status\n",
    "                \n",
    "            elif discrepancy_type == 'missing':\n",
    "                # Skip this transaction (don't add to secondary)\n",
    "                continue\n",
    "        \n",
    "        secondary_transactions.append(secondary_tx)\n",
    "    \n",
    "    # Add some transactions that only exist in the secondary system\n",
    "    extra_count = int(len(primary_transactions) * DATA_CONFIG['extra_transactions_rate'])\n",
    "    account_ids = [tx['account_id'] for tx in primary_transactions]\n",
    "    start_date = min(tx['transaction_date'] for tx in primary_transactions)\n",
    "    end_date = max(tx['transaction_date'] for tx in primary_transactions)\n",
    "    \n",
    "    extra_transactions = generate_transaction_data(\n",
    "        secondary_system,\n",
    "        account_ids,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        count=extra_count\n",
    "    )\n",
    "    \n",
    "    secondary_transactions.extend(extra_transactions)\n",
    "    \n",
    "    return secondary_transactions\n",
    "\n",
    "print(\"‚úì Data generation functions created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Sample Transaction Data\n",
    "\n",
    "**Purpose**: Create realistic banking transaction data for all source systems.\n",
    "\n",
    "### **Data Generation Process**:\n",
    "\n",
    "#### **1. Primary System (Core Banking)**\n",
    "- Generate base transactions with complete information\n",
    "- Use as reference for other systems\n",
    "- Highest data quality and completeness\n",
    "\n",
    "#### **2. Secondary Systems (Card Processor, Payment Gateway)**\n",
    "- Create matching transactions with intentional discrepancies\n",
    "- Introduce various types of errors\n",
    "- Add extra transactions that don't exist in primary system\n",
    "\n",
    "#### **3. Data Quality Features**\n",
    "- Realistic amounts and dates\n",
    "- Proper status distribution\n",
    "- Rich metadata payloads\n",
    "- Consistent account references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üé≤ Generating sample transaction data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üé≤ Generating sample transaction data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úì Data directory: <span style=\"color: #800080; text-decoration-color: #800080\">/opt/bitnami/spark/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">raw</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úì Data directory: \u001b[35m/opt/bitnami/spark/data/\u001b[0m\u001b[95mraw\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Generating account IDs<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Generating account IDs\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'generate_account_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Generate account IDs\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Generating account IDs...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m account_ids = \u001b[43mgenerate_account_ids\u001b[49m(num_accounts=DATA_CONFIG[\u001b[33m'\u001b[39m\u001b[33mnum_accounts\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úì Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(account_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m unique account IDs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSample account IDs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccount_ids[:\u001b[32m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_account_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate sample transaction data\n",
    "print(\"üé≤ Generating sample transaction data...\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = \"/opt/bitnami/spark/data/raw\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "print(f\"‚úì Data directory: {data_dir}\")\n",
    "\n",
    "# Generate account IDs\n",
    "print(\"\\n Generating account IDs...\")\n",
    "account_ids = generate_account_ids(num_accounts=DATA_CONFIG['num_accounts'])\n",
    "print(f\"‚úì Generated {len(account_ids)} unique account IDs\")\n",
    "print(f\"Sample account IDs: {account_ids[:5]}\")\n",
    "\n",
    "# Generate primary transactions (core banking)\n",
    "print(\"\\n Generating primary transactions (core banking)...\")\n",
    "primary_system = 'core_banking'\n",
    "primary_transactions = generate_transaction_data(\n",
    "    primary_system,\n",
    "    account_ids,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    count=DATA_CONFIG['primary_transactions']\n",
    ")\n",
    "\n",
    "print(f\"‚úì Generated {len(primary_transactions)} primary transactions\")\n",
    "print(f\"Date range: {min(tx['transaction_date'] for tx in primary_transactions)} to {max(tx['transaction_date'] for tx in primary_transactions)}\")\n",
    "print(f\"Amount range: ${min(tx['amount'] for tx in primary_transactions):.2f} to ${max(tx['amount'] for tx in primary_transactions):.2f}\")\n",
    "\n",
    "# Generate matching transactions for secondary systems\n",
    "print(\"\\nüîÑ Generating matching transactions for secondary systems...\")\n",
    "secondary_systems = [s for s in SOURCE_SYSTEMS if s != primary_system]\n",
    "all_transactions = {primary_system: primary_transactions}\n",
    "\n",
    "for secondary_system in secondary_systems:\n",
    "    print(f\"\\nüìä Processing {secondary_system}...\")\n",
    "    secondary_transactions = create_matching_transactions(\n",
    "        primary_transactions,\n",
    "        secondary_system,\n",
    "        error_rate=DATA_CONFIG['error_rate']\n",
    "    )\n",
    "    all_transactions[secondary_system] = secondary_transactions\n",
    "    print(f\"‚úì Generated {len(secondary_transactions)} {secondary_system} transactions\")\n",
    "\n",
    "# Summary of generated data\n",
    "print(\"\\nüìä Data Generation Summary:\")\n",
    "total_transactions = sum(len(txs) for txs in all_transactions.values())\n",
    "print(f\"- Total transactions: {total_transactions:,}\")\n",
    "for system, transactions in all_transactions.items():\n",
    "    print(f\"- {system}: {len(transactions):,} transactions\")\n",
    "print(f\"- Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"- Error rate: {DATA_CONFIG['error_rate']*100:.1f}%\")\n",
    "print(f\"- Extra transactions rate: {DATA_CONFIG['extra_transactions_rate']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Data to CSV Files\n",
    "\n",
    "**Purpose**: Save generated data to CSV files for ingestion into Iceberg tables.\n",
    "\n",
    "### **CSV File Strategy**:\n",
    "\n",
    "#### **File Organization**\n",
    "- One CSV file per source system\n",
    "- Consistent naming convention\n",
    "- Proper data type handling\n",
    "\n",
    "#### **Data Format**\n",
    "- DateTime objects converted to strings\n",
    "- JSON payloads properly serialized\n",
    "- Consistent column ordering\n",
    "\n",
    "#### **File Locations**\n",
    "- `/opt/bitnami/spark/data/raw/`\n",
    "- Accessible to Spark for ingestion\n",
    "- Organized by source system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV files\n",
    "print(\" Saving data to CSV files...\")\n",
    "\n",
    "def save_to_csv(transactions, filename):\n",
    "    \"\"\"Save transactions to a CSV file.\"\"\"\n",
    "    df = pd.DataFrame(transactions)\n",
    "    \n",
    "    # Convert datetime objects to strings\n",
    "    for col in ['transaction_date', 'created_at', 'processing_timestamp']:\n",
    "        df[col] = df[col].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"‚úì Saved {len(transactions)} transactions to {filename}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(f\"  Sample data from {filename}:\")\n",
    "    print(f\"  - Columns: {list(df.columns)}\")\n",
    "    print(f\"  - Shape: {df.shape}\")\n",
    "    print(f\"  - Sample transaction_id: {df['transaction_id'].iloc[0]}\")\n",
    "    print(f\"  - Sample amount: ${df['amount'].iloc[0]:.2f}\")\n",
    "    print(f\"  - Sample status: {df['status'].iloc[0]}\")\n",
    "\n",
    "# Save each source system's data\n",
    "csv_files = {}\n",
    "for system, transactions in all_transactions.items():\n",
    "    filename = f\"{data_dir}/{system}_transactions.csv\"\n",
    "    save_to_csv(transactions, filename)\n",
    "    csv_files[system] = filename\n",
    "\n",
    "print(f\"\\nüìÅ CSV files created:\")\n",
    "for system, filename in csv_files.items():\n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f\"- {system}: {filename} ({file_size:,} bytes)\")\n",
    "\n",
    "# Verify files exist and are readable\n",
    "print(\"\\nüîç Verifying CSV files...\")\n",
    "for filename in csv_files.values():\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"‚úì {filename} exists and is readable\")\n",
    "    else:\n",
    "        print(f\"‚úó {filename} not found\")\n",
    "\n",
    "# Show directory contents\n",
    "print(f\"\\n Raw data directory contents:\")\n",
    "!ls -la {data_dir}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Ingest Data into Iceberg Tables\n",
    "\n",
    "**Purpose**: Load CSV data into Iceberg tables using Spark DataFrame operations.\n",
    "\n",
    "### **Ingestion Strategy**:\n",
    "\n",
    "#### **1. CSV Reading**\n",
    "- Use Spark's CSV reader with proper schema inference\n",
    "- Handle datetime parsing correctly\n",
    "- Ensure data type consistency\n",
    "\n",
    "#### **2. Data Transformation**\n",
    "- Convert string dates back to timestamps\n",
    "- Ensure proper decimal precision for amounts\n",
    "- Validate data quality\n",
    "\n",
    "#### **3. Iceberg Writing**\n",
    "- Use Iceberg's write capabilities\n",
    "- Leverage partitioning for performance\n",
    "- Maintain ACID properties\n",
    "\n",
    "#### **4. Error Handling**\n",
    "- Validate data before writing\n",
    "- Handle missing or malformed data\n",
    "- Provide detailed error reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data into Iceberg tables\n",
    "print(\"üì• Ingesting data into Iceberg tables...\")\n",
    "\n",
    "def ingest_csv_to_iceberg(csv_file, table_name):\n",
    "    \"\"\"Ingest CSV file into Iceberg table.\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüîÑ Processing {csv_file}...\")\n",
    "        \n",
    "        # Read CSV file\n",
    "        df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_file)\n",
    "        \n",
    "        print(f\"‚úì Read {df.count()} rows from {csv_file}\")\n",
    "        print(f\"Schema: {df.schema}\")\n",
    "        \n",
    "        # Convert string dates back to timestamps\n",
    "        from pyspark.sql.functions import to_timestamp\n",
    "        \n",
    "        df = df.withColumn(\"transaction_date\", to_timestamp(\"transaction_date\")) \\\n",
    "               .withColumn(\"created_at\", to_timestamp(\"created_at\")) \\\n",
    "               .withColumn(\"processing_timestamp\", to_timestamp(\"processing_timestamp\"))\n",
    "        \n",
    "        # Show sample data\n",
    "        print(f\"\\n Sample data from {csv_file}:\")\n",
    "        df.show(5, truncate=False)\n",
    "        \n",
    "        # Write to the Iceberg table\n",
    "        print(f\"\\nüíæ Writing to {table_name}...\")\n",
    "        df.writeTo(table_name).append()\n",
    "        \n",
    "        print(f\"‚úì Successfully ingested {df.count()} rows into {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error ingesting {csv_file} into {table_name}: {str(e)}\")\n",
    "\n",
    "# Ingest each system's data\n",
    "table_map = {\n",
    "    \"core_banking\": \"minio.banking.source_transactions\",\n",
    "    \"card_processor\": \"minio.banking.source_transactions\",\n",
    "    \"payment_gateway\": \"minio.banking.source_transactions\"\n",
    "}\n",
    "\n",
    "for system, csv_file in csv_files.items():\n",
    "    ingest_csv_to_iceberg(csv_file, table_map[system])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Audit and Validate Data Ingestion\n",
    "\n",
    "**Purpose**: Ensure that data was ingested correctly and is ready for reconciliation.\n",
    "\n",
    "### **Audit Steps**:\n",
    "- Count rows in each table\n",
    "- Check partition distribution\n",
    "- Validate schema and sample data\n",
    "- Confirm data ranges and integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audit and validate data ingestion\n",
    "print(\"üîç Auditing data ingestion...\")\n",
    "\n",
    "for table in tables_to_check:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as count FROM {table}\").collect()[0]['count']\n",
    "        print(f\"‚úì {table}: {count} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {table}: Error - {str(e)}\")\n",
    "\n",
    "# Check partition distribution for source_transactions\n",
    "print(\"\\nüìä Partition distribution for source_transactions:\")\n",
    "try:\n",
    "    partition_df = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            date_trunc('day', transaction_date) as day,\n",
    "            source_system,\n",
    "            COUNT(*) as count\n",
    "        FROM minio.banking.source_transactions\n",
    "        GROUP BY day, source_system\n",
    "        ORDER BY day, source_system\n",
    "    \"\"\")\n",
    "    partition_df.show(10)\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error checking partition distribution: {str(e)}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìã Sample data from source_transactions:\")\n",
    "try:\n",
    "    spark.sql(\"SELECT * FROM minio.banking.source_transactions LIMIT 5\").show(truncate=False)\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error showing sample data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Examine Iceberg File Structure After Data Population\n",
    "\n",
    "**Purpose**: Understand how Iceberg organizes data files after populating with real data.\n",
    "\n",
    "### **What We'll Examine**:\n",
    "1. **Data Directory Structure**: How data files are organized\n",
    "2. **Partition Directories**: Date and source system partitioning\n",
    "3. **Metadata Updates**: How metadata files change with data\n",
    "4. **File Sizes**: Understanding storage requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'warehouse'\n",
    "namespace_prefix = 'banking/'\n",
    "\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "# Initialize MinIO client\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id='minio',\n",
    "    aws_secret_access_key='minio123',\n",
    "    config=Config(signature_version='s3v4'),\n",
    "    region_name='us-east-1'\n",
    ")\n",
    "\n",
    "\n",
    "def list_s3_prefix(prefix, title):\n",
    "    print(f\"\\nüîç {title}\")\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            print(obj['Key'])\n",
    "    else:\n",
    "        print(\"No objects found.\")\n",
    "\n",
    "print(\"üìÅ Examining Iceberg file structure...\")\n",
    "\n",
    "# Banking namespace structure\n",
    "list_s3_prefix(namespace_prefix, \"Banking namespace structure\")\n",
    "\n",
    "# source_transactions table structure\n",
    "list_s3_prefix(namespace_prefix + 'source_transactions/', \"source_transactions table structure\")\n",
    "\n",
    "# source_transactions metadata\n",
    "list_s3_prefix(namespace_prefix + 'source_transactions/metadata/', \"source_transactions metadata\")\n",
    "\n",
    "# reconciliation_results table structure\n",
    "list_s3_prefix(namespace_prefix + 'reconciliation_results/', \"reconciliation_results table structure\")\n",
    "\n",
    "# reconciliation_batches table structure\n",
    "list_s3_prefix(namespace_prefix + 'reconciliation_batches/', \"reconciliation_batches table structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Partitioning - Hive Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç source_transactions data directory <span style=\"font-weight: bold\">(</span>if exists<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç source_transactions data directory \u001b[1m(\u001b[0mif exists\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No files found in this directory.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No files found in this directory.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç <span style=\"color: #808000; text-decoration-color: #808000\">transaction_date_day</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç \u001b[33mtransaction_date_day\u001b[0m=\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m29\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No files found in this directory.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "No files found in this directory.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üîç <span style=\"color: #808000; text-decoration-color: #808000\">transaction_date_day</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>/<span style=\"color: #808000; text-decoration-color: #808000\">source_system</span>=<span style=\"color: #800080; text-decoration-color: #800080\">card_processor</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üîç \u001b[33mtransaction_date_day\u001b[0m=\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m29\u001b[0m/\u001b[33msource_system\u001b[0m=\u001b[35mcard_processor\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">banking/source_transactions/data/<span style=\"color: #808000; text-decoration-color: #808000\">transaction_date_day</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>/<span style=\"color: #808000; text-decoration-color: #808000\">source_system</span>=<span style=\"color: #800080; text-decoration-color: #800080\">card_processor</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">00000</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>-<span style=\"color: #ffff00; text-decoration-color: #ffff00\">a8e7f0d0-e69</span>\n",
       "<span style=\"color: #ffff00; text-decoration-color: #ffff00\">6-4d49-b20e-d8b1fabcb779</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">00018.</span>parquet\n",
       "</pre>\n"
      ],
      "text/plain": [
       "banking/source_transactions/data/\u001b[33mtransaction_date_day\u001b[0m=\u001b[1;36m2025\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m29\u001b[0m/\u001b[33msource_system\u001b[0m=\u001b[35mcard_processor\u001b[0m/\u001b[1;36m00000\u001b[0m-\u001b[1;36m21\u001b[0m-\u001b[93ma8e7f0d0-e69\u001b[0m\n",
       "\u001b[93m6-4d49-b20e-d8b1fabcb779\u001b[0m-\u001b[1;36m0\u001b[0m-\u001b[1;36m00018.\u001b[0mparquet\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bucket_name = 'warehouse'\n",
    "data_prefix = 'banking/source_transactions/data/'\n",
    "\n",
    "def list_s3_dir(prefix, title):\n",
    "    print(f\"\\nüîç {title}\")\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    if 'Contents' in response:\n",
    "        found = False\n",
    "        for obj in response['Contents']:\n",
    "            # Only show objects directly under the prefix (simulate ls)\n",
    "            key = obj['Key']\n",
    "            if key != prefix and '/' not in key[len(prefix):].strip('/'):\n",
    "                print(key)\n",
    "                found = True\n",
    "        if not found:\n",
    "            print(\"No files found in this directory.\")\n",
    "    else:\n",
    "        print(\"Directory not yet created.\")\n",
    "\n",
    "# List the data directory\n",
    "list_s3_dir(data_prefix, \"source_transactions data directory (if exists)\")\n",
    "\n",
    "# List a specific partition directory (change the date as needed)\n",
    "partition_prefix = data_prefix + 'transaction_date_day=2025-06-29/'\n",
    "list_s3_dir(partition_prefix, \"transaction_date_day=2025-06-29\")\n",
    "\n",
    "# List a specific source_system partition (change as needed)\n",
    "source_system_prefix = partition_prefix + 'source_system=card_processor/'\n",
    "list_s3_dir(source_system_prefix, \"transaction_date_day=2025-06-29/source_system=card_processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Phase 2 Summary and Next Steps\n",
    "\n",
    "**Purpose**: Summarize what was accomplished in Phase 2 and prepare for the next phase.\n",
    "\n",
    "### **What We've Accomplished**:\n",
    "- Generated realistic, multi-system banking transaction data\n",
    "- Introduced controlled discrepancies for reconciliation testing\n",
    "- Saved data to CSV files and ingested into Iceberg tables\n",
    "- Validated data quality, partitioning, and schema\n",
    "- Examined Iceberg file structure with real data\n",
    "\n",
    "### **Next Phase Preview**:\n",
    "- Implement reconciliation logic\n",
    "- Analyze and resolve discrepancies\n",
    "- Generate reconciliation reports\n",
    "- Perform advanced Iceberg operations (time travel, schema evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üéâ Phase <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> Complete!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üéâ Phase \u001b[1;36m2\u001b[0m Complete!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"timestamp\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"2025-07-13T18:13:14.860616\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"phase\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Phase 2 - Data Generation and Population\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"status\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"completed\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"data\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"total_transactions\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15073</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"systems\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"core_banking\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"card_processor\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5041</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"payment_gateway\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5032</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"date_range\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"2025-06-13\"</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"2025-07-13\"</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"error_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"extra_transactions_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"files\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"csv_files\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/bitnami/spark/data/raw/core_banking_transactions.csv\"</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/bitnami/spark/data/raw/card_processor_transactions.csv\"</span>,\n",
       "      <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/bitnami/spark/data/raw/payment_gateway_transactions.csv\"</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"data_directory\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/bitnami/spark/data/raw\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"warehouse_directory\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"s3a://warehouse\"</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"tables\"</span>: <span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"source_transactions\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Populated with multi-system transaction data\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"reconciliation_results\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Ready for reconciliation outcomes\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"reconciliation_batches\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Ready for batch metadata\"</span>\n",
       "  <span style=\"font-weight: bold\">}</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"next_steps\"</span>: <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Phase 3: Implement reconciliation logic\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Phase 4: Generate reconciliation reports\"</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Phase 5: Advanced Iceberg features\"</span>\n",
       "  <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"timestamp\"\u001b[0m: \u001b[32m\"2025-07-13T18:13:14.860616\"\u001b[0m,\n",
       "  \u001b[32m\"phase\"\u001b[0m: \u001b[32m\"Phase 2 - Data Generation and Population\"\u001b[0m,\n",
       "  \u001b[32m\"status\"\u001b[0m: \u001b[32m\"completed\"\u001b[0m,\n",
       "  \u001b[32m\"data\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"total_transactions\"\u001b[0m: \u001b[1;36m15073\u001b[0m,\n",
       "    \u001b[32m\"systems\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "      \u001b[32m\"core_banking\"\u001b[0m: \u001b[1;36m5000\u001b[0m,\n",
       "      \u001b[32m\"card_processor\"\u001b[0m: \u001b[1;36m5041\u001b[0m,\n",
       "      \u001b[32m\"payment_gateway\"\u001b[0m: \u001b[1;36m5032\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m\"date_range\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "      \u001b[32m\"2025-06-13\"\u001b[0m,\n",
       "      \u001b[32m\"2025-07-13\"\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m\"error_rate\"\u001b[0m: \u001b[1;36m0.05\u001b[0m,\n",
       "    \u001b[32m\"extra_transactions_rate\"\u001b[0m: \u001b[1;36m0.02\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"files\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"csv_files\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "      \u001b[32m\"/opt/bitnami/spark/data/raw/core_banking_transactions.csv\"\u001b[0m,\n",
       "      \u001b[32m\"/opt/bitnami/spark/data/raw/card_processor_transactions.csv\"\u001b[0m,\n",
       "      \u001b[32m\"/opt/bitnami/spark/data/raw/payment_gateway_transactions.csv\"\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m\"data_directory\"\u001b[0m: \u001b[32m\"/opt/bitnami/spark/data/raw\"\u001b[0m,\n",
       "    \u001b[32m\"warehouse_directory\"\u001b[0m: \u001b[32m\"s3a://warehouse\"\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"tables\"\u001b[0m: \u001b[1m{\u001b[0m\n",
       "    \u001b[32m\"source_transactions\"\u001b[0m: \u001b[32m\"Populated with multi-system transaction data\"\u001b[0m,\n",
       "    \u001b[32m\"reconciliation_results\"\u001b[0m: \u001b[32m\"Ready for reconciliation outcomes\"\u001b[0m,\n",
       "    \u001b[32m\"reconciliation_batches\"\u001b[0m: \u001b[32m\"Ready for batch metadata\"\u001b[0m\n",
       "  \u001b[1m}\u001b[0m,\n",
       "  \u001b[32m\"next_steps\"\u001b[0m: \u001b[1m[\u001b[0m\n",
       "    \u001b[32m\"Phase 3: Implement reconciliation logic\"\u001b[0m,\n",
       "    \u001b[32m\"Phase 4: Generate reconciliation reports\"\u001b[0m,\n",
       "    \u001b[32m\"Phase 5: Advanced Iceberg features\"\u001b[0m\n",
       "  \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">============================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "============================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       " Learning Summary:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       " Learning Summary:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Understanding of realistic data generation for banking scenarios\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Understanding of realistic data generation for banking scenarios\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Experience with multi-system data creation and discrepancy introduction\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Experience with multi-system data creation and discrepancy introduction\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Knowledge of CSV to Iceberg data ingestion process\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Knowledge of CSV to Iceberg data ingestion process\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Familiarity with Iceberg partitioning and data organization\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Familiarity with Iceberg partitioning and data organization\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ Understanding of Iceberg file structure with populated data\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚úÖ Understanding of Iceberg file structure with populated data\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "üöÄ Next: Run Phase <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> notebook for reconciliation logic.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "üöÄ Next: Run Phase \u001b[1;36m3\u001b[0m notebook for reconciliation logic.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate phase summary\n",
    "phase2_summary = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"phase\": \"Phase 2 - Data Generation and Population\",\n",
    "    \"status\": \"completed\",\n",
    "    \"data\": {\n",
    "        \"total_transactions\": total_transactions,\n",
    "        \"systems\": {system: len(transactions) for system, transactions in all_transactions.items()},\n",
    "        \"date_range\": [start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')],\n",
    "        \"error_rate\": DATA_CONFIG['error_rate'],\n",
    "        \"extra_transactions_rate\": DATA_CONFIG['extra_transactions_rate']\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"csv_files\": list(csv_files.values()),\n",
    "        \"data_directory\": data_dir,\n",
    "        \"warehouse_directory\": warehouse_dir\n",
    "    },\n",
    "    \"tables\": {\n",
    "        \"source_transactions\": \"Populated with multi-system transaction data\",\n",
    "        \"reconciliation_results\": \"Ready for reconciliation outcomes\",\n",
    "        \"reconciliation_batches\": \"Ready for batch metadata\"\n",
    "    },\n",
    "    \"next_steps\": [\n",
    "        \"Phase 3: Implement reconciliation logic\",\n",
    "        \"Phase 4: Generate reconciliation reports\",\n",
    "        \"Phase 5: Advanced Iceberg features\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"üéâ Phase 2 Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(phase2_summary, indent=2))\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n Learning Summary:\")\n",
    "print(\"‚úÖ Understanding of realistic data generation for banking scenarios\")\n",
    "print(\"‚úÖ Experience with multi-system data creation and discrepancy introduction\")\n",
    "print(\"‚úÖ Knowledge of CSV to Iceberg data ingestion process\")\n",
    "print(\"‚úÖ Familiarity with Iceberg partitioning and data organization\")\n",
    "print(\"‚úÖ Understanding of Iceberg file structure with populated data\")\n",
    "print(\"\\nüöÄ Next: Run Phase 3 notebook for reconciliation logic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
